{"items":[{"tags":["sql","hadoop","exception","hive","runtime-error"],"owner":{"account_id":23049303,"reputation":1,"user_id":17166379,"user_type":"registered","profile_image":"https://lh3.googleusercontent.com/a-/AOh14Gi40aY9VSbhgqWRir4sV4pgW8nYQf_VO86wWcFVln8=k-s256","display_name":"Gaia B.","link":"https://stackoverflow.com/users/17166379/gaia-b"},"is_answered":false,"view_count":17,"answer_count":0,"score":0,"last_activity_date":1654099050,"creation_date":1654099050,"question_id":72464866,"body_markdown":"I have executed this query on HIVE, using that dataset:\r\nhttps://data.europa.eu/data/datasets/erasmus-mobility-statistics-2014-2019-v2?locale=en:\r\n\r\n``` \r\nselect i.foe, i.pn, i.massimo \r\nfrom \r\n(\r\nSELECT m.foe, m.pn, max(m.somma) AS massimo\r\nFROM\r\n(\r\nselect pn, foe, sum(participants) as somma\r\nfrom erasmus\r\nWHERE foe &lt;&gt; &quot;? Unknown ?&quot; and participants&gt;0\r\ngroup by foe, pn\r\n) as m\r\ngroup by m.foe, m.pn\r\n) as i\r\nwhere i.massimo=\r\n(\r\nselect sum(participants) as somma\r\nfrom erasmus\r\nWHERE foe &lt;&gt; &quot;? Unknown ?&quot; and participants&gt;0 AND i.foe=foe\r\ngroup by foe, pn\r\n) \r\n```\r\n\r\nAt the end of execution I get this error back:\r\n\r\n```\r\n\r\nError: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {&quot;key&quot;:{&quot;_col0&quot;:&quot;Audio-visual techniques and media production&quot;,&quot;_col1&quot;:&quot;AD&quot;},&quot;value&quot;:null}\r\ncaused by: org.apache.hadoop.hive.ql.exec.UDFArgumentException: Scalar subquery expression returns more than one row.\r\n\r\n```\r\n\r\nHow can I solve this? Thank you.","link":"https://stackoverflow.com/questions/72464866/hive-terminal-runtimeexception-after-query-execution","title":"Hive Terminal RuntimeException after query execution","body":"<p>I have executed this query on HIVE, using that dataset:\n<a href=\"https://data.europa.eu/data/datasets/erasmus-mobility-statistics-2014-2019-v2?locale=en\" rel=\"nofollow noreferrer\">https://data.europa.eu/data/datasets/erasmus-mobility-statistics-2014-2019-v2?locale=en</a>:</p>\n<pre><code>select i.foe, i.pn, i.massimo \nfrom \n(\nSELECT m.foe, m.pn, max(m.somma) AS massimo\nFROM\n(\nselect pn, foe, sum(participants) as somma\nfrom erasmus\nWHERE foe &lt;&gt; &quot;? Unknown ?&quot; and participants&gt;0\ngroup by foe, pn\n) as m\ngroup by m.foe, m.pn\n) as i\nwhere i.massimo=\n(\nselect sum(participants) as somma\nfrom erasmus\nWHERE foe &lt;&gt; &quot;? Unknown ?&quot; and participants&gt;0 AND i.foe=foe\ngroup by foe, pn\n) \n</code></pre>\n<p>At the end of execution I get this error back:</p>\n<pre><code>\nError: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {&quot;key&quot;:{&quot;_col0&quot;:&quot;Audio-visual techniques and media production&quot;,&quot;_col1&quot;:&quot;AD&quot;},&quot;value&quot;:null}\ncaused by: org.apache.hadoop.hive.ql.exec.UDFArgumentException: Scalar subquery expression returns more than one row.\n\n</code></pre>\n<p>How can I solve this? Thank you.</p>\n"},{"tags":["python","pandas","dataframe"],"owner":{"account_id":23813409,"reputation":25,"user_id":17821964,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/a7702facff15bce96fdf48039a89299e?s=256&d=identicon&r=PG","display_name":"moxinator","link":"https://stackoverflow.com/users/17821964/moxinator"},"is_answered":true,"view_count":50,"accepted_answer_id":71391531,"answer_count":1,"score":1,"last_activity_date":1646725806,"creation_date":1646725241,"last_edit_date":1646725806,"question_id":71391503,"body_markdown":"I got a weird looking dataset, where every row describes another dataset. &quot;data&quot; in this case is a list which I have converted to a dataframe.\r\n\r\n    result_df = pd.DataFrame(data)\r\n[![enter image description here][1]][1]\r\n\r\n\r\nWhen looking in the first entry of the dataframe above, I see a dataframe with 5 rows. This is the case for every other row. See the dataframe for the first row (row zero) here:\r\n\r\n    result_df[0][0]\r\n    \t_embedded.results|className\t_embedded.results|classId\t_embedded.results|uri\t_embedded.results|searchHit\t_embedded.results|title\t_embedded.results|preferredLabel\t_embedded.results|isTopConceptInScheme\t_embedded.results|isInScheme\t_embedded.results|hasSkillType\t_embedded.results|hasReuseLevel\t_embedded.results|broaderHierarchyConcept\t_embedded.results|_links\t_embedded.results|broaderSkill\tBC_name\r\n       0\tSkill\thttp://data.europa.eu/esco/model#Skill\thttp://data.europa.eu/esco/skill/237db40b-4600...\trange of project control principles\tproject management principles\t{&#39;de&#39;: &#39;Prinzipien des Projektmanagements&#39;, &#39;n...\t[http://data.europa.eu/esco/concept-scheme/mem...\t[http://data.europa.eu/esco/concept-scheme/ski...\t[http://data.europa.eu/esco/skill-type/knowledge]\t[http://data.europa.eu/esco/skill-reuse-level/...\t[http://data.europa.eu/esco/isced-f/0413]\t{&#39;self&#39;: {&#39;href&#39;: &#39;https://ec.europa.eu/esco/a...\tNaN\tProject Financials Control\r\n       1\tSkill\thttp://data.europa.eu/esco/model#Skill\thttp://data.europa.eu/esco/skill/abb9c7f1-6d69...\tOperate projection equipment manually or with ...\toperate projector\t{&#39;de&#39;: &#39;Projektoren bedienen&#39;, &#39;no&#39;: &#39;betjene ...\t[http://data.europa.eu/esco/concept-scheme/mem...\t[http://data.europa.eu/esco/concept-scheme/ski...\t[http://data.europa.eu/esco/skill-type/skill]\t[http://data.europa.eu/esco/skill-reuse-level/...\t[http://data.europa.eu/esco/skill/S8.6.2]\t{&#39;self&#39;: {&#39;href&#39;: &#39;https://ec.europa.eu/esco/a...\tNaN\tProject Financials Control\r\n       2\tSkill\thttp://data.europa.eu/esco/model#Skill\thttp://data.europa.eu/esco/skill/25a713ba-cbc0...\tManage the overall planning, coordination, and...\tmanage railway construction projects\t{&#39;de&#39;: &#39;Bahnbauprojekte leiten&#39;, &#39;no&#39;: &#39;admini...\tNaN\t[http://data.europa.eu/esco/concept-scheme/ski...\t[http://data.europa.eu/esco/skill-type/skill]\t[http://data.europa.eu/esco/skill-reuse-level/...\t[http://data.europa.eu/esco/skill/S4.2.1]\t{&#39;self&#39;: {&#39;href&#39;: &#39;https://ec.europa.eu/esco/a...\t[http://data.europa.eu/esco/skill/fff5bc45-b50...\tProject Financials Control\r\n       3\tSkill\thttp://data.europa.eu/esco/model#Skill\thttp://data.europa.eu/esco/skill/d37bc902-f640...\tprepare financial projections\tprepare financial projections\t{&#39;de&#39;: &#39;Finanzprognosen erstellen&#39;, &#39;no&#39;: &#39;for...\t[http://data.europa.eu/esco/concept-scheme/mem...\t[http://data.europa.eu/esco/concept-scheme/ski...\t[http://data.europa.eu/esco/skill-type/skill]\t[http://data.europa.eu/esco/skill-reuse-level/...\t[http://data.europa.eu/esco/skill/S2.7.3]\t{&#39;self&#39;: {&#39;href&#39;: &#39;https://ec.europa.eu/esco/a...\tNaN\tProject Financials Control\r\n       4\tSkill\thttp://data.europa.eu/esco/model#Skill\thttp://data.europa.eu/esco/skill/7106b5df-e017...\tPRojects IN Controlled Environments, version 2\tPrince2 project management\t{&#39;de&#39;: &#39;Prince2-Projektmanagement&#39;, &#39;no&#39;: &#39;Pri...\tNaN\t[http://data.europa.eu/esco/concept-scheme/ski...\t[http://data.europa.eu/esco/skill-type/knowledge]\t[http://data.europa.eu/esco/skill-reuse-level/...\t[http://data.europa.eu/esco/isced-f/0413]\t{&#39;self&#39;: {&#39;href&#39;: &#39;https://ec.europa.eu/esco/a...\t[http://data.europa.eu/esco/skill/bec4359e-cb9...\tProject Financials Control\r\n\r\nHere&#39;s a screenshot snipped of the dataframe:\r\n[![enter image description here][2]][2]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/ERp6Q.png\r\n  [2]: https://i.stack.imgur.com/WryWh.png\r\n\r\nIs it possible to extract these dataset in every row and append it to one big dataframe? So the resulting dataframe at the end should have the size of &quot;1716 x 5 = 8580&quot;.\r\n\r\nI tried something like this without success:\r\n\r\n    column_names = [&quot;_embedded.results|className&quot;, &quot;_embedded.results|classId&quot;, &quot;_embedded.results|uri&quot;,&quot;_embedded.results|searchHit&quot;, &quot;_embedded.results|title\t&quot;, &quot;_embedded.results|preferredLabel&quot;, &quot;_embedded.results|isTopConceptInScheme&quot;, &quot;embedded.results|isInScheme&quot;,&quot;_embedded.results|hasSkillType&quot;,&quot;_embedded.results|hasReuseLevel&quot;,&quot;_embedded.results|broaderHierarchyConcept&quot;,&quot;_embedded.results|_links&quot;,&quot;_embedded.results|broaderSkill&quot;,&quot;BC_name&quot;]\r\n    my_df = pd.DataFrame(columns = column_names)\r\n\r\n    for index, i in result_df.iterrows():\r\n      for j in i:\r\n        my_df.append(j)","link":"https://stackoverflow.com/questions/71391503/python-extracting-datasets-in-dataset","title":"Python: Extracting Datasets in Dataset","body":"<p>I got a weird looking dataset, where every row describes another dataset. &quot;data&quot; in this case is a list which I have converted to a dataframe.</p>\n<pre><code>result_df = pd.DataFrame(data)\n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/ERp6Q.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ERp6Q.png\" alt=\"enter image description here\" /></a></p>\n<p>When looking in the first entry of the dataframe above, I see a dataframe with 5 rows. This is the case for every other row. See the dataframe for the first row (row zero) here:</p>\n<pre><code>result_df[0][0]\n    _embedded.results|className _embedded.results|classId   _embedded.results|uri   _embedded.results|searchHit _embedded.results|title _embedded.results|preferredLabel    _embedded.results|isTopConceptInScheme  _embedded.results|isInScheme    _embedded.results|hasSkillType  _embedded.results|hasReuseLevel _embedded.results|broaderHierarchyConcept   _embedded.results|_links    _embedded.results|broaderSkill  BC_name\n   0    Skill   http://data.europa.eu/esco/model#Skill  http://data.europa.eu/esco/skill/237db40b-4600...   range of project control principles project management principles   {'de': 'Prinzipien des Projektmanagements', 'n...   [http://data.europa.eu/esco/concept-scheme/mem...   [http://data.europa.eu/esco/concept-scheme/ski...   [http://data.europa.eu/esco/skill-type/knowledge]   [http://data.europa.eu/esco/skill-reuse-level/...   [http://data.europa.eu/esco/isced-f/0413]   {'self': {'href': 'https://ec.europa.eu/esco/a...   NaN Project Financials Control\n   1    Skill   http://data.europa.eu/esco/model#Skill  http://data.europa.eu/esco/skill/abb9c7f1-6d69...   Operate projection equipment manually or with ...   operate projector   {'de': 'Projektoren bedienen', 'no': 'betjene ...   [http://data.europa.eu/esco/concept-scheme/mem...   [http://data.europa.eu/esco/concept-scheme/ski...   [http://data.europa.eu/esco/skill-type/skill]   [http://data.europa.eu/esco/skill-reuse-level/...   [http://data.europa.eu/esco/skill/S8.6.2]   {'self': {'href': 'https://ec.europa.eu/esco/a...   NaN Project Financials Control\n   2    Skill   http://data.europa.eu/esco/model#Skill  http://data.europa.eu/esco/skill/25a713ba-cbc0...   Manage the overall planning, coordination, and...   manage railway construction projects    {'de': 'Bahnbauprojekte leiten', 'no': 'admini...   NaN [http://data.europa.eu/esco/concept-scheme/ski...   [http://data.europa.eu/esco/skill-type/skill]   [http://data.europa.eu/esco/skill-reuse-level/...   [http://data.europa.eu/esco/skill/S4.2.1]   {'self': {'href': 'https://ec.europa.eu/esco/a...   [http://data.europa.eu/esco/skill/fff5bc45-b50...   Project Financials Control\n   3    Skill   http://data.europa.eu/esco/model#Skill  http://data.europa.eu/esco/skill/d37bc902-f640...   prepare financial projections   prepare financial projections   {'de': 'Finanzprognosen erstellen', 'no': 'for...   [http://data.europa.eu/esco/concept-scheme/mem...   [http://data.europa.eu/esco/concept-scheme/ski...   [http://data.europa.eu/esco/skill-type/skill]   [http://data.europa.eu/esco/skill-reuse-level/...   [http://data.europa.eu/esco/skill/S2.7.3]   {'self': {'href': 'https://ec.europa.eu/esco/a...   NaN Project Financials Control\n   4    Skill   http://data.europa.eu/esco/model#Skill  http://data.europa.eu/esco/skill/7106b5df-e017...   PRojects IN Controlled Environments, version 2  Prince2 project management  {'de': 'Prince2-Projektmanagement', 'no': 'Pri...   NaN [http://data.europa.eu/esco/concept-scheme/ski...   [http://data.europa.eu/esco/skill-type/knowledge]   [http://data.europa.eu/esco/skill-reuse-level/...   [http://data.europa.eu/esco/isced-f/0413]   {'self': {'href': 'https://ec.europa.eu/esco/a...   [http://data.europa.eu/esco/skill/bec4359e-cb9...   Project Financials Control\n</code></pre>\n<p>Here's a screenshot snipped of the dataframe:\n<a href=\"https://i.stack.imgur.com/WryWh.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WryWh.png\" alt=\"enter image description here\" /></a></p>\n<p>Is it possible to extract these dataset in every row and append it to one big dataframe? So the resulting dataframe at the end should have the size of &quot;1716 x 5 = 8580&quot;.</p>\n<p>I tried something like this without success:</p>\n<pre><code>column_names = [&quot;_embedded.results|className&quot;, &quot;_embedded.results|classId&quot;, &quot;_embedded.results|uri&quot;,&quot;_embedded.results|searchHit&quot;, &quot;_embedded.results|title &quot;, &quot;_embedded.results|preferredLabel&quot;, &quot;_embedded.results|isTopConceptInScheme&quot;, &quot;embedded.results|isInScheme&quot;,&quot;_embedded.results|hasSkillType&quot;,&quot;_embedded.results|hasReuseLevel&quot;,&quot;_embedded.results|broaderHierarchyConcept&quot;,&quot;_embedded.results|_links&quot;,&quot;_embedded.results|broaderSkill&quot;,&quot;BC_name&quot;]\nmy_df = pd.DataFrame(columns = column_names)\n\nfor index, i in result_df.iterrows():\n  for j in i:\n    my_df.append(j)\n</code></pre>\n"},{"tags":["python","list","dataframe","dictionary"],"owner":{"account_id":23813409,"reputation":25,"user_id":17821964,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/a7702facff15bce96fdf48039a89299e?s=256&d=identicon&r=PG","display_name":"moxinator","link":"https://stackoverflow.com/users/17821964/moxinator"},"is_answered":false,"view_count":65,"answer_count":1,"score":0,"last_activity_date":1645455896,"creation_date":1645455183,"question_id":71208366,"body_markdown":"i got a dataframe from an API call and want to extract the dictionary in the &quot;_embedded_results&quot; column. The dataframe looks as follows:\r\n\r\n    \tBC_id\t                             _embedded.results\r\n    0\t6EAE8B27FCC11ED892E91CE972E580CC\t[{&#39;className&#39;: &#39;Skill&#39;, &#39;classId&#39;: &#39;http://dat...\r\n    1\t7EAE8B27FCC11ED892E91CE972E580CC\t[{&#39;className&#39;: &#39;Skill&#39;, &#39;classId&#39;: &#39;http://dat...\r\n    2\t8EAE8B27FCC11ED892E91CE972E580CC\t[{&#39;className&#39;: &#39;Skill&#39;, &#39;classId&#39;: &#39;http://dat...\r\n    3\t9EAE8B27FCC11ED892E91CE972ED00CC\t[{&#39;className&#39;: &#39;Skill&#39;, &#39;classId&#39;: &#39;http://dat...\r\n    4\t0EAE8B27FCC11ED892E91CE972ED00CC\t[{&#39;className&#39;: &#39;Skill&#39;, &#39;classId&#39;: &#39;http://dat..\r\n\r\nThe &quot;_embedded_results&quot; column (on position 0 for example) in detail looks as follows. For every row, there is a list with 5 different dictionaries: \r\n\r\n    [{&#39;className&#39;: &#39;Skill&#39;,\r\n      &#39;classId&#39;: &#39;http://data.europa.eu/esco/model#Skill&#39;,\r\n      &#39;uri&#39;: &#39;http://data.europa.eu/esco/skill/237db40b-4600-47c0-837f-4a2c4f3014ab&#39;,\r\n      &#39;searchHit&#39;: &#39;range of project control principles&#39;,\r\n      &#39;title&#39;: &#39;project management principles&#39;},\r\n     {&#39;className&#39;: &#39;Skill&#39;,\r\n      &#39;classId&#39;: &#39;http://data.europa.eu/esco/model#Skill&#39;,\r\n      &#39;uri&#39;: &#39;http://data.europa.eu/esco/skill/abb9c7f1-6d69-4feb-913e-6e577d426ea4&#39;,\r\n      &#39;searchHit&#39;: &#39;Operate projection equipment manually or with a control panel.&#39;,\r\n      &#39;title&#39;: &#39;operate projector&#39;},\r\n     ...}]\r\n\r\nNow I want to extract the &quot;title&quot; value of &quot;_embedded_results&quot; and append it as extra column. For example like this at the first entry:  \r\n\r\n    \tBC_id\t                             _embedded.results                                Title1                             Title2                  ...\r\n    0\t6EAE8B27FCC11ED892E91CE972E580CC\t[{&#39;className&#39;: &#39;Skill&#39;, &#39;classId&#39;: &#39;http://dat...   project management principles   operate projector\r\n    1\t7EAE8B27FCC11ED892E91CE972E580CC\t[{&#39;className&#39;: &#39;Skill&#39;, &#39;classId&#39;: &#39;http://dat...\r\n    2\t8EAE8B27FCC11ED892E91CE972E580CC\t[{&#39;className&#39;: &#39;Skill&#39;, &#39;classId&#39;: &#39;http://dat...\r\n    3\t9EAE8B27FCC11ED892E91CE972ED00CC\t[{&#39;className&#39;: &#39;Skill&#39;, &#39;classId&#39;: &#39;http://dat...\r\n    4\t0EAE8B27FCC11ED892E91CE972ED00CC\t[{&#39;className&#39;: &#39;Skill&#39;, &#39;classId&#39;: &#39;http://dat..\r\n\r\nAnother option would be to create a column &quot;title&quot; and append a row for every title.\r\n\r\nI have tried something like this, to extract the titles for every row, but I don&#39;t know how to put this again into the dataframe:\r\n\r\n    my_list = [[x[&#39;title&#39;] for x in list_dict] for list_dict in my_df1[&#39;_embedded.results&#39;]]\r\n\r\n\r\n    my_list[0:2]\r\n    [[&#39;project management principles&#39;,\r\n      &#39;operate projector&#39;,\r\n      &#39;manage railway construction projects&#39;,\r\n      &#39;prepare financial projections&#39;,\r\n      &#39;Prince2 project management&#39;],\r\n     [&#39;project management principles&#39;,\r\n      &#39;operate projector&#39;,\r\n      &#39;manage railway construction projects&#39;,\r\n      &#39;prepare financial projections&#39;,\r\n      &#39;Prince2 project management&#39;]]\r\n\r\nDoes anyone knows how to solve this?\r\nThanks in advance!","link":"https://stackoverflow.com/questions/71208366/python-extract-list-dictionary-column-in-pandas-dataframe","title":"Python: Extract List-Dictionary column in Pandas Dataframe","body":"<p>i got a dataframe from an API call and want to extract the dictionary in the &quot;_embedded_results&quot; column. The dataframe looks as follows:</p>\n<pre><code>    BC_id                                _embedded.results\n0   6EAE8B27FCC11ED892E91CE972E580CC    [{'className': 'Skill', 'classId': 'http://dat...\n1   7EAE8B27FCC11ED892E91CE972E580CC    [{'className': 'Skill', 'classId': 'http://dat...\n2   8EAE8B27FCC11ED892E91CE972E580CC    [{'className': 'Skill', 'classId': 'http://dat...\n3   9EAE8B27FCC11ED892E91CE972ED00CC    [{'className': 'Skill', 'classId': 'http://dat...\n4   0EAE8B27FCC11ED892E91CE972ED00CC    [{'className': 'Skill', 'classId': 'http://dat..\n</code></pre>\n<p>The &quot;_embedded_results&quot; column (on position 0 for example) in detail looks as follows. For every row, there is a list with 5 different dictionaries:</p>\n<pre><code>[{'className': 'Skill',\n  'classId': 'http://data.europa.eu/esco/model#Skill',\n  'uri': 'http://data.europa.eu/esco/skill/237db40b-4600-47c0-837f-4a2c4f3014ab',\n  'searchHit': 'range of project control principles',\n  'title': 'project management principles'},\n {'className': 'Skill',\n  'classId': 'http://data.europa.eu/esco/model#Skill',\n  'uri': 'http://data.europa.eu/esco/skill/abb9c7f1-6d69-4feb-913e-6e577d426ea4',\n  'searchHit': 'Operate projection equipment manually or with a control panel.',\n  'title': 'operate projector'},\n ...}]\n</code></pre>\n<p>Now I want to extract the &quot;title&quot; value of &quot;_embedded_results&quot; and append it as extra column. For example like this at the first entry:</p>\n<pre><code>    BC_id                                _embedded.results                                Title1                             Title2                  ...\n0   6EAE8B27FCC11ED892E91CE972E580CC    [{'className': 'Skill', 'classId': 'http://dat...   project management principles   operate projector\n1   7EAE8B27FCC11ED892E91CE972E580CC    [{'className': 'Skill', 'classId': 'http://dat...\n2   8EAE8B27FCC11ED892E91CE972E580CC    [{'className': 'Skill', 'classId': 'http://dat...\n3   9EAE8B27FCC11ED892E91CE972ED00CC    [{'className': 'Skill', 'classId': 'http://dat...\n4   0EAE8B27FCC11ED892E91CE972ED00CC    [{'className': 'Skill', 'classId': 'http://dat..\n</code></pre>\n<p>Another option would be to create a column &quot;title&quot; and append a row for every title.</p>\n<p>I have tried something like this, to extract the titles for every row, but I don't know how to put this again into the dataframe:</p>\n<pre><code>my_list = [[x['title'] for x in list_dict] for list_dict in my_df1['_embedded.results']]\n\n\nmy_list[0:2]\n[['project management principles',\n  'operate projector',\n  'manage railway construction projects',\n  'prepare financial projections',\n  'Prince2 project management'],\n ['project management principles',\n  'operate projector',\n  'manage railway construction projects',\n  'prepare financial projections',\n  'Prince2 project management']]\n</code></pre>\n<p>Does anyone knows how to solve this?\nThanks in advance!</p>\n"},{"tags":["python","pandas","database","dataframe","download"],"owner":{"account_id":17061453,"reputation":1,"user_id":12412580,"user_type":"registered","profile_image":"https://i.stack.imgur.com/Nd3Ty.jpg?s=256&g=1","display_name":"Phil","link":"https://stackoverflow.com/users/12412580/phil"},"is_answered":false,"view_count":47,"answer_count":1,"score":0,"last_activity_date":1643137774,"creation_date":1643127759,"last_edit_date":1643137774,"question_id":70852123,"body_markdown":"I was wondering how I could access the datasets of the different years from data.europa online (https://data.europa.eu/data/datasets/road-traffic-accidents/), and load them in a pandas dataframe. I tried with the help of the API documentation but didn&#39;t get far. Help is appreciated!\r\n\r\nEdit: I would like to know how to access it online, I know it can be downloaded manually, but accessing the data with a web request is something I was interested in learning. ","link":"https://stackoverflow.com/questions/70852123/python-accessing-data-europa-eu-online-datasets-for-road-traffic-accidents","title":"Python accessing data.europa.eu online datasets for road traffic accidents","body":"<p>I was wondering how I could access the datasets of the different years from data.europa online (<a href=\"https://data.europa.eu/data/datasets/road-traffic-accidents/\" rel=\"nofollow noreferrer\">https://data.europa.eu/data/datasets/road-traffic-accidents/</a>), and load them in a pandas dataframe. I tried with the help of the API documentation but didn't get far. Help is appreciated!</p>\n<p>Edit: I would like to know how to access it online, I know it can be downloaded manually, but accessing the data with a web request is something I was interested in learning.</p>\n"},{"tags":["python","api","url","uri"],"owner":{"user_type":"does_not_exist","display_name":"user15649753"},"is_answered":true,"view_count":52,"accepted_answer_id":68683700,"answer_count":1,"score":0,"last_activity_date":1628272440,"creation_date":1628261370,"question_id":68683580,"body_markdown":"I have a question not sure how I could search for it in the internet to find the answer. and I am at work and should solve it as much as soon posible.\r\n\r\nI am reading URI with the following code:\r\n\r\n    headers = {\r\n        &#39;User-Agent&#39;: &#39;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36&#39;,\r\n        &#39;Accept-Encoding&#39;: &#39;*&#39;,\r\n        &#39;Accept&#39;: &#39;text/html&#39;,\r\n        &#39;Accept-Language&#39;: &#39;*&#39;}\r\n    import requests\r\n    \r\n    link = &quot;http://data.europa.eu/esco/isco/C0110&quot;\r\n    f = requests.get(link,headers=headers)\r\n    print(f.text)\r\n\r\nIf you look at `http://data.europa.eu/esco/isco/C0110` you see that there is a descriptin for `Commissioned armed forces officers`\r\n\r\nI need to extract just the description part. \r\n\r\nThere are thousands of line but the part that I want is this:\r\n\r\n\r\n      &lt;h2&gt;Description&lt;/h2&gt;\r\n      &lt;pre&gt;Commissioned armed forces officers provide leadership and management to organizational units in the armed forces and/or perform similar tasks to those performed in a variety of civilian occupations outside the armed forces. This group includes all members of the armed forces holding the rank of second lieutenant (or equivalent) or higher.\r\n\r\nis it possible? I have 1000 data like this so I can&#39;t do it manually. I need description part.","link":"https://stackoverflow.com/questions/68683580/how-to-grab-specific-part-of-a-uri","title":"how to grab specific part of a uri?","body":"<p>I have a question not sure how I could search for it in the internet to find the answer. and I am at work and should solve it as much as soon posible.</p>\n<p>I am reading URI with the following code:</p>\n<pre><code>headers = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36',\n    'Accept-Encoding': '*',\n    'Accept': 'text/html',\n    'Accept-Language': '*'}\nimport requests\n\nlink = &quot;http://data.europa.eu/esco/isco/C0110&quot;\nf = requests.get(link,headers=headers)\nprint(f.text)\n</code></pre>\n<p>If you look at <code>http://data.europa.eu/esco/isco/C0110</code> you see that there is a descriptin for <code>Commissioned armed forces officers</code></p>\n<p>I need to extract just the description part.</p>\n<p>There are thousands of line but the part that I want is this:</p>\n<pre><code>  &lt;h2&gt;Description&lt;/h2&gt;\n  &lt;pre&gt;Commissioned armed forces officers provide leadership and management to organizational units in the armed forces and/or perform similar tasks to those performed in a variety of civilian occupations outside the armed forces. This group includes all members of the armed forces holding the rank of second lieutenant (or equivalent) or higher.\n</code></pre>\n<p>is it possible? I have 1000 data like this so I can't do it manually. I need description part.</p>\n"},{"tags":["python","url","request"],"owner":{"user_type":"does_not_exist","display_name":"user15649753"},"is_answered":true,"view_count":81,"accepted_answer_id":68679254,"answer_count":2,"score":-1,"last_activity_date":1628251696,"creation_date":1628240735,"last_edit_date":1628242688,"question_id":68678991,"body_markdown":"I want to read a url in python but I get error with different ways:\r\n\r\n    import urllib\r\n    link = &quot;http://data.europa.eu/esco/isco/C0110&quot;\r\n    f = urllib.urlopen(link)\r\n    myfile = f.read()\r\n    print(myfile)\r\n\r\n    HTTPError: HTTP Error 406: Not Acceptable\r\n\r\n    link = &quot;http://data.europa.eu/esco/isco/C0110&quot;\r\n    f = requests.get(link)\r\n    print(f)\r\n\r\n    &lt;Response [406]&gt;\r\n\r\nAny idea?","link":"https://stackoverflow.com/questions/68678991/why-cant-i-read-a-url-in-python","title":"Why can&#39;t I read a url in python?","body":"<p>I want to read a url in python but I get error with different ways:</p>\n<pre><code>import urllib\nlink = &quot;http://data.europa.eu/esco/isco/C0110&quot;\nf = urllib.urlopen(link)\nmyfile = f.read()\nprint(myfile)\n\nHTTPError: HTTP Error 406: Not Acceptable\n\nlink = &quot;http://data.europa.eu/esco/isco/C0110&quot;\nf = requests.get(link)\nprint(f)\n\n&lt;Response [406]&gt;\n</code></pre>\n<p>Any idea?</p>\n"},{"tags":["javascript","velo"],"owner":{"account_id":21884311,"reputation":1,"user_id":16172142,"user_type":"registered","profile_image":"https://lh3.googleusercontent.com/a/AATXAJyEc0rK0iubRQsX9trEeiwzi5zRj3BAS8ADShY=k-s256","display_name":"Niko L","link":"https://stackoverflow.com/users/16172142/niko-l"},"is_answered":false,"view_count":236,"answer_count":1,"score":0,"last_activity_date":1623318423,"creation_date":1623217745,"last_edit_date":1623318423,"question_id":67898299,"body_markdown":"I&#39;m trying to set the background image of a wix strip to change images by looping through an array when it is hovered on. I do not see any errors being thrown in the editor, however it is still not working. This is my current code. \r\n\r\n    $w.onReady(function () {\r\n    var image1 = &quot;https://workful.com/blog/wp-content/uploads/2019/10/Women-in-Small-Business.jpg&quot;;\r\n\r\n    var image2 = &quot;https://data.europa.eu/sites/default/files/news/2020-25-3.jpg&quot;;\r\n\r\n    var image3 = &quot;https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fstartswithabang%2Ffiles%2F2017%2F10%2FTiny_bit_of_U.jpg&quot;;\r\n\r\n\r\n    var Background_imagez = [image1,image2,image3];\r\n\r\n    let playing = false;\r\n    let current = 0;\r\n\r\n     const run = () =&gt; {\r\n    setTimeout(() =&gt; {\r\n        $w(&#39;#columnStrip1&#39;).background.src = Background_imagez[current];\r\n        if (current &lt; Background_imagez.length) {\r\n            current++;\r\n        } else { repeat() }\r\n       }, 500);\r\n       }\r\n\r\n      const repeat = () =&gt; {\r\n        current = 0;\r\n          run();\r\n         }\r\n\r\n     $w(&#39;#text59&#39;).onMouseIn(() =&gt; {\r\n        playing = true;\r\n        while (playing) { run() }\r\n        })\r\n\r\n        $w(&#39;#columnStrip1&#39;).onMouseOut(() =&gt; {\r\n        playing = false;\r\n        current = 0;\r\n        $w(&#39;#columnStrip1&#39;).background.src = \r\n         &#39;https://wallpapercave.com/wp/wp2831956.png&#39; || \r\n        &#39;https://images.unsplash.com/flagged/photo-1593005510329-8a4035a7238f?ixlib=rb-1.2.1&amp;ixid=MnwxMjA3fDB8MHxleHBsb3JlLWZlZWR8MXx8fGVufDB8fHx8&amp;w=1000&amp;q=80&#39;; // Default    \r\n        })\r\n\r\n\r\n        });\r\n\r\n\r\n\r\n\r\n\r\n\r\n```\r\n","link":"https://stackoverflow.com/questions/67898299/loop-through-images-and-set-background-on-hover-in-wix-velo","title":"Loop through images and set background on hover in wix velo","body":"<p>I'm trying to set the background image of a wix strip to change images by looping through an array when it is hovered on. I do not see any errors being thrown in the editor, however it is still not working. This is my current code.</p>\n<pre><code>$w.onReady(function () {\nvar image1 = &quot;https://workful.com/blog/wp-content/uploads/2019/10/Women-in-Small-Business.jpg&quot;;\n\nvar image2 = &quot;https://data.europa.eu/sites/default/files/news/2020-25-3.jpg&quot;;\n\nvar image3 = &quot;https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fstartswithabang%2Ffiles%2F2017%2F10%2FTiny_bit_of_U.jpg&quot;;\n\n\nvar Background_imagez = [image1,image2,image3];\n\nlet playing = false;\nlet current = 0;\n\n const run = () =&gt; {\nsetTimeout(() =&gt; {\n    $w('#columnStrip1').background.src = Background_imagez[current];\n    if (current &lt; Background_imagez.length) {\n        current++;\n    } else { repeat() }\n   }, 500);\n   }\n\n  const repeat = () =&gt; {\n    current = 0;\n      run();\n     }\n\n $w('#text59').onMouseIn(() =&gt; {\n    playing = true;\n    while (playing) { run() }\n    })\n\n    $w('#columnStrip1').onMouseOut(() =&gt; {\n    playing = false;\n    current = 0;\n    $w('#columnStrip1').background.src = \n     'https://wallpapercave.com/wp/wp2831956.png' || \n    'https://images.unsplash.com/flagged/photo-1593005510329-8a4035a7238f?ixlib=rb-1.2.1&amp;ixid=MnwxMjA3fDB8MHxleHBsb3JlLWZlZWR8MXx8fGVufDB8fHx8&amp;w=1000&amp;q=80'; // Default    \n    })\n\n\n    });\n</code></pre>\n<pre><code></code></pre>\n"},{"tags":["http","uri"],"owner":{"account_id":14775011,"reputation":41,"user_id":10670234,"user_type":"registered","profile_image":"https://lh4.googleusercontent.com/-gDN4iTCshDg/AAAAAAAAAAI/AAAAAAAAAAA/AGDgw-i-p09J3YCJISTE0R8BGaEMbOmtJA/mo/photo.jpg?sz=256","display_name":"Evim","link":"https://stackoverflow.com/users/10670234/evim"},"is_answered":false,"view_count":289,"answer_count":0,"score":4,"last_activity_date":1605871712,"creation_date":1542548726,"last_edit_date":1542552743,"question_id":53361560,"body_markdown":"I would like to save the classification from esco into a file using the uri.\r\n\r\nI would like to have skills and competences pillars and words or every level.\r\n\r\nI can see in every page that there is the specific uri.\r\n\r\nHowever it is time consuming and possible to not the whole information. Is there any way to find the full list of uris for skills pillar.\r\n\r\nexample of uri get call\r\n\r\n    https://ec.europa.eu/esco/api/resource/skill?uri=http://data.europa.eu/esco/skill/a59708e3-e654-4e37-8b8a-741c3b756eee&amp;language=en%20HTTP/1.1\r\n\r\n[Example page][1] with concept uri\r\n\r\n\r\n  [1]: https://ec.europa.eu/esco/portal/skill","link":"https://stackoverflow.com/questions/53361560/list-of-all-uris","title":"List of all uris","body":"<p>I would like to save the classification from esco into a file using the uri.</p>\n\n<p>I would like to have skills and competences pillars and words or every level.</p>\n\n<p>I can see in every page that there is the specific uri.</p>\n\n<p>However it is time consuming and possible to not the whole information. Is there any way to find the full list of uris for skills pillar.</p>\n\n<p>example of uri get call</p>\n\n<pre><code>https://ec.europa.eu/esco/api/resource/skill?uri=http://data.europa.eu/esco/skill/a59708e3-e654-4e37-8b8a-741c3b756eee&amp;language=en%20HTTP/1.1\n</code></pre>\n\n<p><a href=\"https://ec.europa.eu/esco/portal/skill\" rel=\"nofollow noreferrer\">Example page</a> with concept uri</p>\n"},{"tags":["r","ggplot2","shiny","reactive"],"owner":{"account_id":16962751,"reputation":3,"user_id":12269486,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/8ca12244664ae6d722386a95cb6d356b?s=256&d=identicon&r=PG&f=1","display_name":"franzi_dee","link":"https://stackoverflow.com/users/12269486/franzi-dee"},"is_answered":true,"view_count":549,"accepted_answer_id":62782690,"answer_count":1,"score":0,"last_activity_date":1594150986,"creation_date":1594149581,"question_id":62782423,"body_markdown":"I want to build a shiny app using Covid-19 data (https://data.europa.eu/euodp/de/data/dataset/covid-19-coronavirus-data) and I would like to show barplot with ggplot where you can see the development of worldwide cases or deaths over time. I would furthermore like to have a dateRangeInput in which you can set a time period. At the same time I have on the y axis either the possibility to choose from selectInput either the variable &quot;cases&quot; or &quot;deaths&quot;. I can do this separately but I can&#39;t figure out how to have this in one final plot. \r\nIt works with the time range if I use this code: \r\n```\r\nui &lt;- fluidPage(\r\n  titlePanel(&quot;Covid-19 by Country&quot;),\r\n  sidebarLayout(\r\n    sidebarPanel(\r\n      selectInput(inputId = &quot;y&quot;, label = &quot;Y-Axe:&quot;, \r\n                  choices=c(&quot;cases&quot;, &quot;deaths&quot;), \r\n                  selected = &quot;cases&quot;),\r\n      dateRangeInput(&quot;datum&quot;, &quot;Zeitraum ausw&#228;hlen&quot;, start = min(covid_worldwide$dateRep), end = max(covid_worldwide$dateRep), min = min(covid_worldwide$dateRep), max = max(covid_worldwide$dateRep), format = &quot;dd.mm.yyyy&quot;, language = &quot;de&quot;)\r\n    ),\r\n    mainPanel(\r\n      plotOutput(&quot;covidPlot&quot;) \r\n    )\r\n  )\r\n)\r\nserver &lt;- function(input, output, session) {\r\n  s &lt;- reactive({\r\n   covid_worldwide %&gt;%\r\n      filter( \r\n        as.Date(dateRep) &gt;= as.Date(input$datum[1]),\r\n        as.Date(dateRep) &lt;= as.Date(input$datum[2])\r\n      )\r\n  })\r\n  output$covidPlot &lt;- renderPlot({\r\n      ggplot(data= s(), aes(x = dateRep, y = cases)) +\r\n        geom_bar(stat=&quot;identity&quot;, fill=&quot;red&quot;) + theme_classic() + xlab(&quot;Zeitraum&quot;) + ylab(&quot;Anzahl&quot;)\r\n    }\r\n  )}\r\n\r\nshinyApp(ui = ui, server = server)\r\n``` \r\nIt works also if I do not change the time period but give two different variables for the y-axis, see following code (the UI is the same as above): \r\n```\r\nserver &lt;- function(input, output, session) {\r\n  s &lt;- reactive({\r\n  covid_worldwide %&gt;%\r\n      filter(\r\n        as.Date(dateRep) &gt;= as.Date(input$datum[1]),\r\n        as.Date(dateRep) &lt;= as.Date(input$datum[2])\r\n      )\r\n  })\r\n  \r\n  yvar &lt;- reactive({\r\n    if ( &quot;cases&quot; %in% input$y) return(covid_worldwide$cases)\r\n    if ( &quot;deaths&quot; %in% input$y) return(covid_worldwide$deaths)\r\n  })\r\n  output$covidPlot &lt;- renderPlot({\r\n    \r\n      ggplot(data= s(), aes(x = dateRep, y = yvar())) +\r\n        geom_bar(stat=&quot;identity&quot;, fill=&quot;red&quot;) + theme_classic() + xlab(&quot;Zeitraum&quot;) + ylab(&quot;Anzahl&quot;)\r\n    }\r\n  )}\r\n\r\nshinyApp(ui = ui, server = server)\r\n```\r\nBut if I then try to change the time period in the shiny app I receive this error: &quot;Aesthetics must be either length 1 or the same as the data (26852): y&quot;\r\nDoes anyone have an idea on how to make the two things in one ggplot barplot work? Thank you in advance! ","link":"https://stackoverflow.com/questions/62782423/r-shiny-how-to-filter-by-time-range-on-the-x-axis-and-simultaneously-have-two","title":"[R Shiny]: How to filter by time range on the x-axis and simultaneously have two different variables on the y axis in R Shiny app","body":"<p>I want to build a shiny app using Covid-19 data (<a href=\"https://data.europa.eu/euodp/de/data/dataset/covid-19-coronavirus-data\" rel=\"nofollow noreferrer\">https://data.europa.eu/euodp/de/data/dataset/covid-19-coronavirus-data</a>) and I would like to show barplot with ggplot where you can see the development of worldwide cases or deaths over time. I would furthermore like to have a dateRangeInput in which you can set a time period. At the same time I have on the y axis either the possibility to choose from selectInput either the variable &quot;cases&quot; or &quot;deaths&quot;. I can do this separately but I can't figure out how to have this in one final plot.\nIt works with the time range if I use this code:</p>\n<pre><code>ui &lt;- fluidPage(\n  titlePanel(&quot;Covid-19 by Country&quot;),\n  sidebarLayout(\n    sidebarPanel(\n      selectInput(inputId = &quot;y&quot;, label = &quot;Y-Axe:&quot;, \n                  choices=c(&quot;cases&quot;, &quot;deaths&quot;), \n                  selected = &quot;cases&quot;),\n      dateRangeInput(&quot;datum&quot;, &quot;Zeitraum auswählen&quot;, start = min(covid_worldwide$dateRep), end = max(covid_worldwide$dateRep), min = min(covid_worldwide$dateRep), max = max(covid_worldwide$dateRep), format = &quot;dd.mm.yyyy&quot;, language = &quot;de&quot;)\n    ),\n    mainPanel(\n      plotOutput(&quot;covidPlot&quot;) \n    )\n  )\n)\nserver &lt;- function(input, output, session) {\n  s &lt;- reactive({\n   covid_worldwide %&gt;%\n      filter( \n        as.Date(dateRep) &gt;= as.Date(input$datum[1]),\n        as.Date(dateRep) &lt;= as.Date(input$datum[2])\n      )\n  })\n  output$covidPlot &lt;- renderPlot({\n      ggplot(data= s(), aes(x = dateRep, y = cases)) +\n        geom_bar(stat=&quot;identity&quot;, fill=&quot;red&quot;) + theme_classic() + xlab(&quot;Zeitraum&quot;) + ylab(&quot;Anzahl&quot;)\n    }\n  )}\n\nshinyApp(ui = ui, server = server)\n</code></pre>\n<p>It works also if I do not change the time period but give two different variables for the y-axis, see following code (the UI is the same as above):</p>\n<pre><code>server &lt;- function(input, output, session) {\n  s &lt;- reactive({\n  covid_worldwide %&gt;%\n      filter(\n        as.Date(dateRep) &gt;= as.Date(input$datum[1]),\n        as.Date(dateRep) &lt;= as.Date(input$datum[2])\n      )\n  })\n  \n  yvar &lt;- reactive({\n    if ( &quot;cases&quot; %in% input$y) return(covid_worldwide$cases)\n    if ( &quot;deaths&quot; %in% input$y) return(covid_worldwide$deaths)\n  })\n  output$covidPlot &lt;- renderPlot({\n    \n      ggplot(data= s(), aes(x = dateRep, y = yvar())) +\n        geom_bar(stat=&quot;identity&quot;, fill=&quot;red&quot;) + theme_classic() + xlab(&quot;Zeitraum&quot;) + ylab(&quot;Anzahl&quot;)\n    }\n  )}\n\nshinyApp(ui = ui, server = server)\n</code></pre>\n<p>But if I then try to change the time period in the shiny app I receive this error: &quot;Aesthetics must be either length 1 or the same as the data (26852): y&quot;\nDoes anyone have an idea on how to make the two things in one ggplot barplot work? Thank you in advance!</p>\n"},{"tags":["python","semantic-web","ontology"],"owner":{"account_id":12932178,"reputation":49,"user_id":9350849,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/dd0ceeeead98947c1fc82a72590fd82e?s=256&d=identicon&r=PG&f=1","display_name":"Utkarsh Dwivedi","link":"https://stackoverflow.com/users/9350849/utkarsh-dwivedi"},"is_answered":false,"view_count":748,"answer_count":0,"score":2,"last_activity_date":1582177269,"creation_date":1582177269,"question_id":60313576,"body_markdown":"**Objective**\r\n\r\nI am trying to build an Ontology-based semantic search engine specific to our data.\r\n\r\n**Problem Statement**\r\n\r\nOur data is just a bunch of sentences and what I want is to give a phrase and get back the sentences which are:\r\n\r\nSimilar to that phrase\r\n\r\n - Has a part of a sentence that is similar to the phrase \r\n - A sentence which is having contextually similar meanings\r\n\r\nLet me try giving you an example suppose I search for the phrase &quot;Buying Experience&quot;, I should get the sentences like:\r\n\r\n* I never thought car buying could take less than 30 minutes to sign and buy.\r\n* I found a car that I liked and the purchase process was straightforward and easy\r\n* I absolutely hated going car shopping, but today I’m glad I did\r\n\r\nThe search term will always be one to three-word phrases. Ex: buying experience, driving comfort, infotainment system, interiors, mileage, performance, seating comfort, staff behavior.\r\n\r\n**Implementation explored already**\r\n\r\nOpenSemanticSearch&lt;br&gt;AWS Comprehend\r\n\r\n**Current Implementation**\r\n\r\nRight now I am exploring one implementation (&#39;Holmes Extractor&#39;) which mostly suites the objective I am trying to achieve. For my use case, I am using &#39;Topic Matching&#39; available in Holmes.\r\n&lt;br&gt;Holmes has already incorporated many important concepts in its design such as NER, pronoun resolution, word embedding based similarity, ontology-based extraction, which makes this implementation even more promising. \r\n\r\n**What I have tried so far on Holmes**\r\n\r\n1. Manually curated a labeled set with sentences\r\n2. Registered and serialized our dataset with unique label id for each document (sentence)\r\n3. For comparison prepared a template to get precision, recall, and f1_score of each iteration of running queries (search query is the same as the label)\r\n4. Using spaCy&#39;s &#39;en_core_web_lg&#39; for word embedding\r\n\r\nScore template looks something like:\r\nQuery | Predicted Rows | Actual Number of rows in the queried set | Precision | Recall | f1_score\r\n\r\n5. Please find below the parameters used in each iteration. For all the iterations, generated the scores for Manager.overall_similarity_threshold in range(0.0 to 1.0) and topic_match_documents_returning_dictionaries_against.embedding_penalty in range(0.0 to 1.0)\r\n\r\n**Iteration 1:** \r\n\r\nWithout any Ontology and Manager.embedding_based_matching_on_root_words=False\r\n\r\n**Iteration 2:** \r\n\r\nWithout any Ontology and Manager.embedding_based_matching_on_root_words=True\r\n\r\n*Build a custom Ontology using Protege, which is specific to our data set*\r\n\r\n**Iteration 3:** \r\n\r\nWith custom Ontology and Manager.embedding_based_matching_on_root_words=False, Ontology.symmetric_matching=True\r\n\r\n**Iteration 4:** \r\n\r\nWith custom Ontology and Manager.embedding_based_matching_on_root_words=True, Ontology.symmetric_matching=True\r\n&lt;br&gt;At this stage, I can observe that\r\n&lt;br&gt;custom Ontology,\r\n&lt;br&gt;Manager.embedding_based_matching_on_root_words=True,\r\n&lt;br&gt;Manager.overall_similarity_threshold in range (0.6-0.8),\r\n&lt;br&gt;topic_match_documents_returning_dictionaries_against.embedding_penalty in range in range(0.6-0.8),\r\n&lt;br&gt;together are producing very strong scores.\r\n\r\n*average scores for 0.8 -&gt; precision: 0.78, recall: 0.712, f1_score: 0.738*\r\n&lt;br&gt;*average scores for 0.7 -&gt; precision: 0.738, recall: 0.7435, f1_score: 0.726*\r\n\r\n&lt;br&gt;Still, results are not that accurate even after providing custom ontology, because of a lack of stemming keywords in the Ontology graph.\r\n&lt;br&gt;For example, if in Ontology we have given something like Mileage-&gt;fuel efficiency, fuel economy\r\n&lt;br&gt;Holmes will not match sentences with fuel efficient under Mileage, since &quot;fuel efficient&quot; is not mentioned in the Graph\r\n\r\n**Iteration 5:** \r\n\r\nWith custom Ontology and Manager.embedding_based_matching_on_root_words=False, Ontology.symmetric_matching=False\r\n\r\n**Iteration 6:** \r\n\r\nWith custom Ontology and Manager.embedding_based_matching_on_root_words=True, Ontology.symmetric_matching=False\r\n\r\n**Iteration 7:** \r\n\r\nAlong with Iteration 4 parameters, and  &lt;br&gt;topic_match_documents_returning_dictionaries_against.tied_result_quotient in range(0.9 to 0.1)\r\n&lt;br&gt;Again results are better in 0.8-0.9 range\r\n\r\n**Iteration 8:** \r\n\r\nI had pre-downloaded ontologies from a few sources:\r\n&lt;br&gt;Automobile Ontology:\r\n&lt;br&gt;https://github.com/mfhepp/schemaorg/blob/automotive/data/schema.rdfa\r\n&lt;br&gt;Vehicle Sales Ontology:\r\n&lt;br&gt;http://www.heppnetz.de/ontologies/vso/ns\r\n&lt;br&gt;Product Ontology:\r\n&lt;br&gt;http://www.productontology.org/dump.rdf\r\n&lt;br&gt;Mesh Thesaurus:\r\n&lt;br&gt;https://data.europa.eu/euodp/en/data/dataset/eurovoc\r\n&lt;br&gt;English thesaurus:\r\n&lt;br&gt;https://github.com/mromanello/skosifaurus\r\n&lt;br&gt;https://raw.githubusercontent.com/mromanello/skosifaurus/master/thesaurus.rdf\r\n&lt;br&gt;General Ontologies:\r\n&lt;br&gt;https://databus.dbpedia.org/dbpedia/collections/pre-release-2019-08-30\r\n&lt;br&gt;https://wiki.dbpedia.org/Downloads2015-04#dbpedia-ontology\r\n&lt;br&gt;https://lod-cloud.net/dataset/dbpedia\r\n&lt;br&gt;https://wiki.dbpedia.org/services-resources/ontology\r\n&lt;br&gt;https://meta.wikimedia.org/wiki/Data_dump_torrents#English_Wikipedia\r\n&lt;br&gt;https://tools.wmflabs.org/wikidata-exports/rdf/\r\n&lt;br&gt;&lt;br&gt;All the above ontologies are available in either ttl, n3 or rdf format. And holmes extractor (implicitly RDFlib) works on OWL syntax. Therefore, the conversion of the given formats to the OWL format for heavy files is another challenge.\r\n&lt;br&gt;I have tried loading the first 4 ontologies on Holmes after conversion to OWL. But the conversion process takes time as well. Also, loading big ontologies on Holmes itself is taking a good amount of time.\r\n\r\n&lt;br&gt;As per Holmes documentation, Holmes works best with the ontologies that have been built for specific subject domains and use cases.\r\n\r\n**What next**\r\n\r\nThe challenges which I am facing here are:\r\n\r\n1. Finding the proper Ontologies available around customer experience in the automobile domain\r\n2. Making the conversion process of ontologies faster\r\n3. How can we easily generate the domain-specific ontology from our existing data\r\n4. Configuring the right set of parameters along with Ontology to get more accurate results for search phrase queries\r\n\r\nAny help will be appreciated. Thanks a lot for the help in advance ","link":"https://stackoverflow.com/questions/60313576/how-to-find-or-create-ontologies-for-specific-domain","title":"How to find or create Ontologies for specific domain?","body":"<p><strong>Objective</strong></p>\n\n<p>I am trying to build an Ontology-based semantic search engine specific to our data.</p>\n\n<p><strong>Problem Statement</strong></p>\n\n<p>Our data is just a bunch of sentences and what I want is to give a phrase and get back the sentences which are:</p>\n\n<p>Similar to that phrase</p>\n\n<ul>\n<li>Has a part of a sentence that is similar to the phrase </li>\n<li>A sentence which is having contextually similar meanings</li>\n</ul>\n\n<p>Let me try giving you an example suppose I search for the phrase \"Buying Experience\", I should get the sentences like:</p>\n\n<ul>\n<li>I never thought car buying could take less than 30 minutes to sign and buy.</li>\n<li>I found a car that I liked and the purchase process was straightforward and easy</li>\n<li>I absolutely hated going car shopping, but today I’m glad I did</li>\n</ul>\n\n<p>The search term will always be one to three-word phrases. Ex: buying experience, driving comfort, infotainment system, interiors, mileage, performance, seating comfort, staff behavior.</p>\n\n<p><strong>Implementation explored already</strong></p>\n\n<p>OpenSemanticSearch<br>AWS Comprehend</p>\n\n<p><strong>Current Implementation</strong></p>\n\n<p>Right now I am exploring one implementation ('Holmes Extractor') which mostly suites the objective I am trying to achieve. For my use case, I am using 'Topic Matching' available in Holmes.\n<br>Holmes has already incorporated many important concepts in its design such as NER, pronoun resolution, word embedding based similarity, ontology-based extraction, which makes this implementation even more promising. </p>\n\n<p><strong>What I have tried so far on Holmes</strong></p>\n\n<ol>\n<li>Manually curated a labeled set with sentences</li>\n<li>Registered and serialized our dataset with unique label id for each document (sentence)</li>\n<li>For comparison prepared a template to get precision, recall, and f1_score of each iteration of running queries (search query is the same as the label)</li>\n<li>Using spaCy's 'en_core_web_lg' for word embedding</li>\n</ol>\n\n<p>Score template looks something like:\nQuery | Predicted Rows | Actual Number of rows in the queried set | Precision | Recall | f1_score</p>\n\n<ol start=\"5\">\n<li>Please find below the parameters used in each iteration. For all the iterations, generated the scores for Manager.overall_similarity_threshold in range(0.0 to 1.0) and topic_match_documents_returning_dictionaries_against.embedding_penalty in range(0.0 to 1.0)</li>\n</ol>\n\n<p><strong>Iteration 1:</strong> </p>\n\n<p>Without any Ontology and Manager.embedding_based_matching_on_root_words=False</p>\n\n<p><strong>Iteration 2:</strong> </p>\n\n<p>Without any Ontology and Manager.embedding_based_matching_on_root_words=True</p>\n\n<p><em>Build a custom Ontology using Protege, which is specific to our data set</em></p>\n\n<p><strong>Iteration 3:</strong> </p>\n\n<p>With custom Ontology and Manager.embedding_based_matching_on_root_words=False, Ontology.symmetric_matching=True</p>\n\n<p><strong>Iteration 4:</strong> </p>\n\n<p>With custom Ontology and Manager.embedding_based_matching_on_root_words=True, Ontology.symmetric_matching=True\n<br>At this stage, I can observe that\n<br>custom Ontology,\n<br>Manager.embedding_based_matching_on_root_words=True,\n<br>Manager.overall_similarity_threshold in range (0.6-0.8),\n<br>topic_match_documents_returning_dictionaries_against.embedding_penalty in range in range(0.6-0.8),\n<br>together are producing very strong scores.</p>\n\n<p><em>average scores for 0.8 -> precision: 0.78, recall: 0.712, f1_score: 0.738</em>\n<br><em>average scores for 0.7 -> precision: 0.738, recall: 0.7435, f1_score: 0.726</em></p>\n\n<p><br>Still, results are not that accurate even after providing custom ontology, because of a lack of stemming keywords in the Ontology graph.\n<br>For example, if in Ontology we have given something like Mileage->fuel efficiency, fuel economy\n<br>Holmes will not match sentences with fuel efficient under Mileage, since \"fuel efficient\" is not mentioned in the Graph</p>\n\n<p><strong>Iteration 5:</strong> </p>\n\n<p>With custom Ontology and Manager.embedding_based_matching_on_root_words=False, Ontology.symmetric_matching=False</p>\n\n<p><strong>Iteration 6:</strong> </p>\n\n<p>With custom Ontology and Manager.embedding_based_matching_on_root_words=True, Ontology.symmetric_matching=False</p>\n\n<p><strong>Iteration 7:</strong> </p>\n\n<p>Along with Iteration 4 parameters, and  <br>topic_match_documents_returning_dictionaries_against.tied_result_quotient in range(0.9 to 0.1)\n<br>Again results are better in 0.8-0.9 range</p>\n\n<p><strong>Iteration 8:</strong> </p>\n\n<p>I had pre-downloaded ontologies from a few sources:\n<br>Automobile Ontology:\n<br><a href=\"https://github.com/mfhepp/schemaorg/blob/automotive/data/schema.rdfa\" rel=\"nofollow noreferrer\">https://github.com/mfhepp/schemaorg/blob/automotive/data/schema.rdfa</a>\n<br>Vehicle Sales Ontology:\n<br><a href=\"http://www.heppnetz.de/ontologies/vso/ns\" rel=\"nofollow noreferrer\">http://www.heppnetz.de/ontologies/vso/ns</a>\n<br>Product Ontology:\n<br><a href=\"http://www.productontology.org/dump.rdf\" rel=\"nofollow noreferrer\">http://www.productontology.org/dump.rdf</a>\n<br>Mesh Thesaurus:\n<br><a href=\"https://data.europa.eu/euodp/en/data/dataset/eurovoc\" rel=\"nofollow noreferrer\">https://data.europa.eu/euodp/en/data/dataset/eurovoc</a>\n<br>English thesaurus:\n<br><a href=\"https://github.com/mromanello/skosifaurus\" rel=\"nofollow noreferrer\">https://github.com/mromanello/skosifaurus</a>\n<br><a href=\"https://raw.githubusercontent.com/mromanello/skosifaurus/master/thesaurus.rdf\" rel=\"nofollow noreferrer\">https://raw.githubusercontent.com/mromanello/skosifaurus/master/thesaurus.rdf</a>\n<br>General Ontologies:\n<br><a href=\"https://databus.dbpedia.org/dbpedia/collections/pre-release-2019-08-30\" rel=\"nofollow noreferrer\">https://databus.dbpedia.org/dbpedia/collections/pre-release-2019-08-30</a>\n<br><a href=\"https://wiki.dbpedia.org/Downloads2015-04#dbpedia-ontology\" rel=\"nofollow noreferrer\">https://wiki.dbpedia.org/Downloads2015-04#dbpedia-ontology</a>\n<br><a href=\"https://lod-cloud.net/dataset/dbpedia\" rel=\"nofollow noreferrer\">https://lod-cloud.net/dataset/dbpedia</a>\n<br><a href=\"https://wiki.dbpedia.org/services-resources/ontology\" rel=\"nofollow noreferrer\">https://wiki.dbpedia.org/services-resources/ontology</a>\n<br><a href=\"https://meta.wikimedia.org/wiki/Data_dump_torrents#English_Wikipedia\" rel=\"nofollow noreferrer\">https://meta.wikimedia.org/wiki/Data_dump_torrents#English_Wikipedia</a>\n<br><a href=\"https://tools.wmflabs.org/wikidata-exports/rdf/\" rel=\"nofollow noreferrer\">https://tools.wmflabs.org/wikidata-exports/rdf/</a>\n<br><br>All the above ontologies are available in either ttl, n3 or rdf format. And holmes extractor (implicitly RDFlib) works on OWL syntax. Therefore, the conversion of the given formats to the OWL format for heavy files is another challenge.\n<br>I have tried loading the first 4 ontologies on Holmes after conversion to OWL. But the conversion process takes time as well. Also, loading big ontologies on Holmes itself is taking a good amount of time.</p>\n\n<p><br>As per Holmes documentation, Holmes works best with the ontologies that have been built for specific subject domains and use cases.</p>\n\n<p><strong>What next</strong></p>\n\n<p>The challenges which I am facing here are:</p>\n\n<ol>\n<li>Finding the proper Ontologies available around customer experience in the automobile domain</li>\n<li>Making the conversion process of ontologies faster</li>\n<li>How can we easily generate the domain-specific ontology from our existing data</li>\n<li>Configuring the right set of parameters along with Ontology to get more accurate results for search phrase queries</li>\n</ol>\n\n<p>Any help will be appreciated. Thanks a lot for the help in advance </p>\n"},{"tags":["python-3.x","urllib","http.client"],"owner":{"account_id":11679564,"reputation":11,"user_id":8551799,"user_type":"registered","profile_image":"https://lh4.googleusercontent.com/-QzB1UeBiar4/AAAAAAAAAAI/AAAAAAAAADs/tex9K-9paRc/photo.jpg?sz=256","display_name":"veerendra bhadrachalam","link":"https://stackoverflow.com/users/8551799/veerendra-bhadrachalam"},"is_answered":true,"view_count":131,"accepted_answer_id":59083731,"answer_count":1,"score":1,"last_activity_date":1574926371,"creation_date":1574404483,"last_edit_date":1574406541,"question_id":58988736,"body_markdown":"```\r\nimport http.client\r\nimport urllib.parse\r\n\r\ndef unshorten_url(url):\r\n    parsed = urllib.parse.urlparse(url)\r\n    h = http.client.HTTPConnection(parsed.netloc)\r\n    resource = parsed.path\r\n    if parsed.query != &quot;&quot;:\r\n        resource += &quot;?&quot; + parsed.query\r\n    h.request(&#39;HEAD&#39;, resource )\r\n    response = h.getresponse()\r\n    if response.status/100 == 3 and response.getheader(&#39;Location&#39;):\r\n        return unshorten_url(response.getheader(&#39;Location&#39;)) # changed to process chains of short urls\r\n    else:\r\n        return url\r\n\r\nunshorten_url(&quot;http://data.europa.eu/esco/occupation/00030d09-2b3a-4efd-87cc-c4ea39d27c34&quot;)\r\n```\r\n\r\n**Input will be** : \r\nhttp://data.europa.eu/esco/occupation/00030d09-2b3a-4efd-87cc-c4ea39d27c34 #yes the same is returned.&#39;\r\n\r\n**Output URL after unshorten which i need** : https://ec.europa.eu/esco/portal/occupation?uri=http%3A%2F%2Fdata.europa.eu%2Fesco%2Foccupation%2F00030d09-2b3a-4efd-87cc-c4ea39d27c34&amp;conceptLanguage=en&amp;full=true#&amp;uri=http://data.europa.eu/esco/occupation/00030d09-2b3a-4efd-87cc-c4ea39d27c34&#39;","link":"https://stackoverflow.com/questions/58988736/how-can-i-unshorten-a-url-in-python-3","title":"How can I unshorten a URL in python 3","body":"<pre><code>import http.client\nimport urllib.parse\n\ndef unshorten_url(url):\n    parsed = urllib.parse.urlparse(url)\n    h = http.client.HTTPConnection(parsed.netloc)\n    resource = parsed.path\n    if parsed.query != \"\":\n        resource += \"?\" + parsed.query\n    h.request('HEAD', resource )\n    response = h.getresponse()\n    if response.status/100 == 3 and response.getheader('Location'):\n        return unshorten_url(response.getheader('Location')) # changed to process chains of short urls\n    else:\n        return url\n\nunshorten_url(\"http://data.europa.eu/esco/occupation/00030d09-2b3a-4efd-87cc-c4ea39d27c34\")\n</code></pre>\n\n<p><strong>Input will be</strong> : \n<a href=\"http://data.europa.eu/esco/occupation/00030d09-2b3a-4efd-87cc-c4ea39d27c34\" rel=\"nofollow noreferrer\">http://data.europa.eu/esco/occupation/00030d09-2b3a-4efd-87cc-c4ea39d27c34</a> #yes the same is returned.'</p>\n\n<p><strong>Output URL after unshorten which i need</strong> : <a href=\"https://ec.europa.eu/esco/portal/occupation?uri=http%3A%2F%2Fdata.europa.eu%2Fesco%2Foccupation%2F00030d09-2b3a-4efd-87cc-c4ea39d27c34&amp;conceptLanguage=en&amp;full=true#&amp;uri=http://data.europa.eu/esco/occupation/00030d09-2b3a-4efd-87cc-c4ea39d27c34\" rel=\"nofollow noreferrer\">https://ec.europa.eu/esco/portal/occupation?uri=http%3A%2F%2Fdata.europa.eu%2Fesco%2Foccupation%2F00030d09-2b3a-4efd-87cc-c4ea39d27c34&amp;conceptLanguage=en&amp;full=true#&amp;uri=http://data.europa.eu/esco/occupation/00030d09-2b3a-4efd-87cc-c4ea39d27c34</a>'</p>\n"},{"tags":["send","endpoint","wso2-enterprise-integrator","wso2-esb"],"owner":{"account_id":12500635,"reputation":53,"user_id":9099215,"user_type":"registered","profile_image":"https://i.stack.imgur.com/bhvm1.jpg?s=256&g=1","display_name":"Dr. Giuseppe Proietti ","link":"https://stackoverflow.com/users/9099215/dr-giuseppe-proietti"},"is_answered":false,"view_count":492,"answer_count":1,"score":1,"last_activity_date":1567510382,"creation_date":1567508280,"last_edit_date":1655153515,"question_id":57770294,"body_markdown":"When i try to call a remote web-service using a dynamic uri-template in send mediator, i receive this error.\r\nThe url of the resource to call is : https://ec.europa.eu/esco/api/resource/skill?uri=http://data.europa.eu/esco/skill/a59708e3-e654-4e37-8b8a-741c3b756eee&amp;language=it \r\n\r\n\r\n\r\n\r\nFor this purpose i use below in-sequence and out-sequence:\r\n\r\n    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\r\n    &lt;sequence name=&quot;EscoInSequence&quot; xmlns=&quot;http://ws.apache.org/ns/synapse&quot;&gt;\r\n        &lt;property expression=&quot;$url:resource&quot; name=&quot;resource&quot; scope=&quot;default&quot;\r\n            type=&quot;STRING&quot; xmlns:ns=&quot;http://org.apache.synapse/xsd&quot;/&gt;\r\n        &lt;property expression=&quot;$url:uri&quot; name=&quot;uri&quot;\r\n            scope=&quot;default&quot; type=&quot;STRING&quot; xmlns:ns=&quot;http://org.apache.synapse/xsd&quot;/&gt;\r\n        &lt;property expression=&quot;$url:language&quot; name=&quot;language&quot; scope=&quot;default&quot;\r\n            type=&quot;STRING&quot; xmlns:ns=&quot;http://org.apache.synapse/xsd&quot;/&gt;\r\n        &lt;property\r\n            expression=&quot;concat(&#39;https://ec.europa.eu/esco/api/resource/&#39;,$ctx:resource,&#39;?uri=&#39;,$ctx:uri,&#39;&amp;amp;language=&#39;,$ctx:language)&quot;\r\n            name=&quot;UrlToEsco&quot; scope=&quot;default&quot; type=&quot;STRING&quot; xmlns:ns=&quot;http://org.apache.synapse/xsd&quot;/&gt;\r\n        &lt;payloadFactory media-type=&quot;text&quot;&gt;\r\n            &lt;format&gt;$1&lt;/format&gt;\r\n            &lt;args&gt;\r\n                &lt;arg evaluator=&quot;xml&quot; expression=&quot;$ctx:UrlToEsco&quot;\r\n                    literal=&quot;false&quot; xmlns:ns=&quot;http://org.apache.synapse/xsd&quot;/&gt;\r\n            &lt;/args&gt;\r\n        &lt;/payloadFactory&gt;\r\n        &lt;send&gt;\r\n            &lt;endpoint&gt;\r\n                &lt;http method=&quot;GET&quot; uri-template=&quot;{UrlToEsco}&quot;/&gt;\r\n            &lt;/endpoint&gt;\r\n        &lt;/send&gt;\r\n        &lt;enrich&gt;\r\n            &lt;source clone=&quot;true&quot; type=&quot;body&quot;/&gt;\r\n            &lt;target action=&quot;child&quot; property=&quot;rispostaEsco&quot; type=&quot;property&quot;/&gt;\r\n        &lt;/enrich&gt;\r\n        &lt;loopback/&gt;\r\n    &lt;/sequence&gt;\r\n    \r\n    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\r\n    &lt;sequence name=&quot;EscoOutSequence&quot; xmlns=&quot;http://ws.apache.org/ns/synapse&quot;&gt;\r\n        &lt;send/&gt;\r\n    &lt;/sequence&gt;\r\n\r\n\r\nWhen i try to call my api using a static uri ( https://ec.europa.eu/esco/api/resource/skill?uri=http://data.europa.eu/esco/skill/a59708e3-e654-4e37-8b8a-741c3b756eee&amp;language=it ) i haven&#39;t problem, but when i use `UrlToEsco` property i obtain this error   :\r\n\r\n&gt; TID[-1234] [EI] [2019-09-03 12:31:53,029] ERROR\r\n&gt; {org.apache.synapse.core.axis2.Axis2Sender} - Unexpected error during\r\n&gt; sending message out\r\n&gt; org.apache.axis2.description.ClientUtils.inferOutTransport(ClientUtils.java:86)\r\n&gt; org.apache.synapse.core.axis2.DynamicAxisOperation$DynamicOperationClient.executeImpl(DynamicAxisOperation.java:116)\r\n&gt; org.apache.axis2.client.OperationClient.execute(OperationClient.java:149)\r\n&gt; org.apache.synapse.core.axis2.Axis2FlexibleMEPClient.send(Axis2FlexibleMEPClient.java:603)\r\n&gt; org.apache.synapse.core.axis2.Axis2Sender.sendOn(Axis2Sender.java:85)\r\n&gt; org.apache.synapse.core.axis2.Axis2SynapseEnvironment.send(Axis2SynapseEnvironment.java:547)\r\n&gt; org.apache.synapse.endpoints.AbstractEndpoint.send(AbstractEndpoint.java:384)\r\n&gt; org.apache.synapse.endpoints.HTTPEndpoint.send(HTTPEndpoint.java:85)\r\n&gt; org.apache.synapse.mediators.builtin.SendMediator.mediate(SendMediator.java:123)\r\n&gt; org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:108)\r\n&gt; org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:70)\r\n&gt; org.apache.synapse.mediators.base.SequenceMediator.mediate(SequenceMediator.java:158)\r\n&gt; org.apache.synapse.rest.Resource.process(Resource.java:364)\r\n&gt; org.apache.synapse.rest.API.process(API.java:399)\r\n&gt; org.apache.synapse.rest.RESTRequestHandler.apiProcess(RESTRequestHandler.java:123)\r\n&gt; org.apache.synapse.rest.RESTRequestHandler.dispatchToAPI(RESTRequestHandler.java:101)\r\n&gt; org.apache.synapse.rest.RESTRequestHandler.process(RESTRequestHandler.java:69)\r\n&gt; org.apache.synapse.core.axis2.Axis2SynapseEnvironment.injectMessage(Axis2SynapseEnvironment.java:303)\r\n&gt; org.apache.synapse.core.axis2.SynapseMessageReceiver.receive(SynapseMessageReceiver.java:92)\r\n&gt; org.apache.axis2.engine.AxisEngine.receive(AxisEngine.java:180)\r\n&gt; org.apache.synapse.transport.passthru.ServerWorker.processNonEntityEnclosingRESTHandler(ServerWorker.java:337)\r\n&gt; org.apache.synapse.transport.passthru.ServerWorker.run(ServerWorker.java:158)\r\n&gt; org.apache.axis2.transport.base.threads.NativeWorkerPool$1.run(NativeWorkerPool.java:172)\r\n&gt; java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n&gt; java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n&gt; java.lang.Thread.run(Thread.java:745)\r\n\r\n","link":"https://stackoverflow.com/questions/57770294/unexpected-error-during-sending-message-out-error-org-apache-synapse-core-axi","title":"Unexpected error during sending message out - ERROR {org.apache.synapse.core.axis2.Axis2Sender}","body":"<p>When i try to call a remote web-service using a dynamic uri-template in send mediator, i receive this error.\nThe url of the resource to call is : <a href=\"https://ec.europa.eu/esco/api/resource/skill?uri=http://data.europa.eu/esco/skill/a59708e3-e654-4e37-8b8a-741c3b756eee&amp;language=it\" rel=\"nofollow noreferrer\">https://ec.europa.eu/esco/api/resource/skill?uri=http://data.europa.eu/esco/skill/a59708e3-e654-4e37-8b8a-741c3b756eee&amp;language=it</a> </p>\n\n<p>For this purpose i use below in-sequence and out-sequence:</p>\n\n<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;sequence name=\"EscoInSequence\" xmlns=\"http://ws.apache.org/ns/synapse\"&gt;\n    &lt;property expression=\"$url:resource\" name=\"resource\" scope=\"default\"\n        type=\"STRING\" xmlns:ns=\"http://org.apache.synapse/xsd\"/&gt;\n    &lt;property expression=\"$url:uri\" name=\"uri\"\n        scope=\"default\" type=\"STRING\" xmlns:ns=\"http://org.apache.synapse/xsd\"/&gt;\n    &lt;property expression=\"$url:language\" name=\"language\" scope=\"default\"\n        type=\"STRING\" xmlns:ns=\"http://org.apache.synapse/xsd\"/&gt;\n    &lt;property\n        expression=\"concat('https://ec.europa.eu/esco/api/resource/',$ctx:resource,'?uri=',$ctx:uri,'&amp;amp;language=',$ctx:language)\"\n        name=\"UrlToEsco\" scope=\"default\" type=\"STRING\" xmlns:ns=\"http://org.apache.synapse/xsd\"/&gt;\n    &lt;payloadFactory media-type=\"text\"&gt;\n        &lt;format&gt;$1&lt;/format&gt;\n        &lt;args&gt;\n            &lt;arg evaluator=\"xml\" expression=\"$ctx:UrlToEsco\"\n                literal=\"false\" xmlns:ns=\"http://org.apache.synapse/xsd\"/&gt;\n        &lt;/args&gt;\n    &lt;/payloadFactory&gt;\n    &lt;send&gt;\n        &lt;endpoint&gt;\n            &lt;http method=\"GET\" uri-template=\"{UrlToEsco}\"/&gt;\n        &lt;/endpoint&gt;\n    &lt;/send&gt;\n    &lt;enrich&gt;\n        &lt;source clone=\"true\" type=\"body\"/&gt;\n        &lt;target action=\"child\" property=\"rispostaEsco\" type=\"property\"/&gt;\n    &lt;/enrich&gt;\n    &lt;loopback/&gt;\n&lt;/sequence&gt;\n\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;sequence name=\"EscoOutSequence\" xmlns=\"http://ws.apache.org/ns/synapse\"&gt;\n    &lt;send/&gt;\n&lt;/sequence&gt;\n</code></pre>\n\n<p>When i try to call my api using a static uri ( <a href=\"https://ec.europa.eu/esco/api/resource/skill?uri=http://data.europa.eu/esco/skill/a59708e3-e654-4e37-8b8a-741c3b756eee&amp;language=it\" rel=\"nofollow noreferrer\">https://ec.europa.eu/esco/api/resource/skill?uri=http://data.europa.eu/esco/skill/a59708e3-e654-4e37-8b8a-741c3b756eee&amp;language=it</a> ) i haven't problem, but when i use <code>UrlToEsco</code> property i obtain this error   :</p>\n\n<blockquote>\n  <p>TID[-1234] [EI] [2019-09-03 12:31:53,029] ERROR\n  {org.apache.synapse.core.axis2.Axis2Sender} - Unexpected error during\n  sending message out\n  org.apache.axis2.description.ClientUtils.inferOutTransport(ClientUtils.java:86)\n  org.apache.synapse.core.axis2.DynamicAxisOperation$DynamicOperationClient.executeImpl(DynamicAxisOperation.java:116)\n  org.apache.axis2.client.OperationClient.execute(OperationClient.java:149)\n  org.apache.synapse.core.axis2.Axis2FlexibleMEPClient.send(Axis2FlexibleMEPClient.java:603)\n  org.apache.synapse.core.axis2.Axis2Sender.sendOn(Axis2Sender.java:85)\n  org.apache.synapse.core.axis2.Axis2SynapseEnvironment.send(Axis2SynapseEnvironment.java:547)\n  org.apache.synapse.endpoints.AbstractEndpoint.send(AbstractEndpoint.java:384)\n  org.apache.synapse.endpoints.HTTPEndpoint.send(HTTPEndpoint.java:85)\n  org.apache.synapse.mediators.builtin.SendMediator.mediate(SendMediator.java:123)\n  org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:108)\n  org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:70)\n  org.apache.synapse.mediators.base.SequenceMediator.mediate(SequenceMediator.java:158)\n  org.apache.synapse.rest.Resource.process(Resource.java:364)\n  org.apache.synapse.rest.API.process(API.java:399)\n  org.apache.synapse.rest.RESTRequestHandler.apiProcess(RESTRequestHandler.java:123)\n  org.apache.synapse.rest.RESTRequestHandler.dispatchToAPI(RESTRequestHandler.java:101)\n  org.apache.synapse.rest.RESTRequestHandler.process(RESTRequestHandler.java:69)\n  org.apache.synapse.core.axis2.Axis2SynapseEnvironment.injectMessage(Axis2SynapseEnvironment.java:303)\n  org.apache.synapse.core.axis2.SynapseMessageReceiver.receive(SynapseMessageReceiver.java:92)\n  org.apache.axis2.engine.AxisEngine.receive(AxisEngine.java:180)\n  org.apache.synapse.transport.passthru.ServerWorker.processNonEntityEnclosingRESTHandler(ServerWorker.java:337)\n  org.apache.synapse.transport.passthru.ServerWorker.run(ServerWorker.java:158)\n  org.apache.axis2.transport.base.threads.NativeWorkerPool$1.run(NativeWorkerPool.java:172)\n  java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n  java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n  java.lang.Thread.run(Thread.java:745)</p>\n</blockquote>\n"},{"tags":["java","sparql","rdf","jena","semantic-web"],"owner":{"account_id":12317919,"reputation":309,"user_id":8987824,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/5c53e30157dbbd73cd6067ffe1f038fe?s=256&d=identicon&r=PG&f=1","display_name":"alordlord","link":"https://stackoverflow.com/users/8987824/alordlord"},"is_answered":false,"view_count":1379,"answer_count":1,"score":1,"last_activity_date":1564680945,"creation_date":1563873471,"question_id":57160747,"body_markdown":"I have an rdf file which looks somewhat like this (but it is actually larger):\r\n\r\n```\r\n@prefix skos-xl: &lt;http://www.w3.org/2008/05/skos-xl#&gt; .\r\n@prefix dct:   &lt;http://purl.org/dc/terms/&gt; .\r\n@prefix adms:  &lt;http://www.w3.org/ns/adms#&gt; .\r\n@prefix esco:  &lt;http://data.europa.eu/esco/model#&gt; .\r\n@prefix rdf:   &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .\r\n@prefix org:   &lt;http://www.w3.org/ns/org#&gt; .\r\n@prefix iso-thes: &lt;http://purl.org/iso25964/skos-thes#&gt; .\r\n@prefix xsd:   &lt;http://www.w3.org/2001/XMLSchema#&gt; .\r\n@prefix skos:  &lt;http://www.w3.org/2004/02/skos/core#&gt; .\r\n@prefix rdfs:  &lt;http://www.w3.org/2000/01/rdf-schema#&gt; .\r\n@prefix prov:  &lt;http://www.w3.org/ns/prov#&gt; .\r\n@prefix foaf:  &lt;http://xmlns.com/foaf/0.1/&gt; .\r\n\r\n\r\n&lt;http://data.europa.eu/esco/skill/238343b1-7b51-42b3-a9ed-cf24d3a236e7&gt;\r\n        a                       skos:Concept , esco:MemberConcept , esco:Skill ;\r\n        esco:referenceLanguage  &quot;en&quot;^^xsd:language ;\r\n        esco:skillReuseLevel    &lt;http://data.europa.eu/esco/skill-reuse-level/transversal&gt; ;\r\n        esco:skillType          &lt;http://data.europa.eu/esco/skill-type/skill&gt; ;\r\n        dct:description         &lt;http://data.europa.eu/esco/node-literal/447a21ac-f4e0-41e1-a478-1b7cd4c29af8&gt; , &lt;http://data.europa.eu/esco/node-literal/d9f98a36-44fb-4318-bfd9-6ac6b520b034&gt; ;\r\n        iso-thes:status         &quot;released&quot; ;\r\n        skos:altLabel           &quot;reconocer las carencias en competencias digitales&quot;@es , &quot;bearna&#237; maidir le cumas digiteach a aithint&quot;@ga , &quot;identificere manglende digitale kundskaber&quot;@da , &quot;digitale vaardigheidskloven identificeren&quot;@nl , &quot;detectar las deficiencias en competencias digitales&quot;@es , &quot;behoeften aan digitale vaardigheden herkennen&quot;@nl , &quot;παροχή υποστήριξης για την αντιμετώπιση ελλείψεων όσον αφορά την ψηφιακή ικανότητα&quot;@el , &quot;detectar las lagunas en competencias digitales&quot;@es , &quot;tunnistaa digitaalisten taitojen puutteet&quot;@fi , &quot;L&#252;cken bei den IKT-Kompetenzen erkennen&quot;@de ;\r\n        skos:broader            &lt;http://data.europa.eu/esco/skill/7e5147d1-60b1-4a68-804b-1f5cb0396b91&gt; ;\r\n        skos:broaderTransitive  &lt;http://data.europa.eu/esco/skill/7e5147d1-60b1-4a68-804b-1f5cb0396b91&gt; ;\r\n        skos:inScheme           &lt;http://data.europa.eu/esco/concept-scheme/skill-ict-groups&gt; ;\r\n        skos:prefLabel          &quot;digitale vaardigheidskloven herkennen&quot;@nl , &quot;εντοπισμός ελλείψεων όσον αφορά την ψηφιακή ικανότητα&quot;@el , [...] .\r\n\r\n```\r\n\r\nI have been reading a lot on the topic, but still I dont quite understand how I could convert this file to csv (or even JSON would do) with Java. So far I have been using the following script to extract all triples that exist in a graph and print them out in a console:\r\n\r\n```\r\npackage semanticweb;\r\n\r\nimport org.apache.jena.query.Query;\r\nimport org.apache.jena.query.QueryExecution;\r\nimport org.apache.jena.query.QueryExecutionFactory;\r\nimport org.apache.jena.query.QueryFactory;\r\nimport org.apache.jena.query.QuerySolution;\r\nimport org.apache.jena.query.ResultSet;\r\nimport org.apache.jena.rdf.model.Model;\r\nimport org.apache.jena.rdf.model.ModelFactory;\r\n\r\npublic class Main {\r\n\r\n\tpublic static void main(String[] args) {\r\n\t\t// TODO Auto-generated method stub\r\n\t\tgetData();\r\n\t}\r\n\r\n\tstatic void getData(){\r\n\t\t\r\n\t\tModel model = ModelFactory.createDefaultModel() ;\r\n\t\tmodel.read(&quot;C:/Users/andri/eclipse-workspace/semanticweb/ict_skills_collection.ttl&quot;);\r\n\t\t\r\n\t\tString queryString = &quot;PREFIX skos-xl: &lt;http://www.w3.org/2008/05/skos-xl#&gt;&quot; +\r\n\t\t\t\t&quot;PREFIX dct:   &lt;http://purl.org/dc/terms/&gt;&quot; +\r\n\t\t\t\t&quot;PREFIX adms:  &lt;http://www.w3.org/ns/adms#&gt;&quot; +\r\n\t\t\t\t&quot;PREFIX esco:  &lt;http://data.europa.eu/esco/model#&gt;&quot; +\r\n\t\t\t\t&quot;PREFIX rdf:   &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;&quot; +\r\n\t\t\t\t&quot;PREFIX org:   &lt;http://www.w3.org/ns/org#&gt;&quot;+\r\n\t\t\t\t&quot;PREFIX iso-thes: &lt;http://purl.org/iso25964/skos-thes#&gt;&quot;+\r\n\t\t\t\t&quot;PREFIX xsd:   &lt;http://www.w3.org/2001/XMLSchema#&gt;&quot; +\r\n\t\t\t\t&quot;PREFIX skos:  &lt;http://www.w3.org/2004/02/skos/core#&gt;&quot; +\r\n\t\t\t\t&quot;PREFIX rdfs:  &lt;http://www.w3.org/2000/01/rdf-schema#&gt;&quot; +\r\n\t\t\t\t&quot;PREFIX prov:  &lt;http://www.w3.org/ns/prov#&gt;&quot;+\r\n\t\t\t\t&quot;PREFIX foaf:  &lt;http://xmlns.com/foaf/0.1/&gt;&quot; + \t\r\n                &quot;SELECT *&quot;+\r\n                 &quot;WHERE { ?s ?p ?o }&quot;; \r\n\t\t\t\t\t\t\t\r\n\t\t\r\n\t\tQuery query = QueryFactory.create(queryString);\r\n\t\tQueryExecution qexec = QueryExecutionFactory.create(query, model);\r\n\t\t\r\n\t\ttry {\r\n\t\t\t\r\n\t\t ResultSet results = qexec.execSelect();\r\n\t\t while(results.hasNext()) {\r\n\t\t\t QuerySolution qsol = results.nextSolution();\r\n\t\t\t System.out.println(qsol.toString());\r\n\t\t }\r\n\t\t}\r\n\t\t\tfinally {\r\n\t\t\t\tqexec.close();\r\n\t\t\t}\t\r\n\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t}\r\n\r\n}\r\n```\r\n\r\nThe console output looks somewhat like this:\r\n```\r\n( ?p = &lt;http://www.w3.org/2004/02/skos/core#prefLabel&gt; ) ( ?o = &quot;Defizite bei der digitalen Kompetenz ermitteln&quot;@de ) ( ?s = &lt;http://data.europa.eu/esco/skill/238343b1-7b51-42b3-a9ed-cf24d3a236e7&gt; ) -&gt; [Root]\r\n( ?p = &lt;http://www.w3.org/2004/02/skos/core#prefLabel&gt; ) ( ?o = &quot;identifikovat nedostatky v digitalnych kompetenciach&quot;@sk ) ( ?s = &lt;http://data.europa.eu/esco/skill/238343b1-7b51-42b3-a9ed-cf24d3a236e7&gt; ) -&gt; [Root]\r\n( ?p = &lt;http://www.w3.org/2004/02/skos/core#prefLabel&gt; ) ( ?o = &quot;identificar lacunas nas competencias digitais&quot;@pt ) ( ?s = &lt;http://data.europa.eu/esco/skill/238343b1-7b51-42b3-a9ed-cf24d3a236e7&gt; ) -&gt; [Root]\r\n```\r\n\r\nDoes anyone know how I could proceed in converting this triple format to csv? Do I need to understand what these triples represent exactly in order to do this? I appreciate any help you can provide","link":"https://stackoverflow.com/questions/57160747/how-to-export-sparql-query-result-to-csv","title":"How to export SPARQL query result to csv?","body":"<p>I have an rdf file which looks somewhat like this (but it is actually larger):</p>\n\n<pre><code>@prefix skos-xl: &lt;http://www.w3.org/2008/05/skos-xl#&gt; .\n@prefix dct:   &lt;http://purl.org/dc/terms/&gt; .\n@prefix adms:  &lt;http://www.w3.org/ns/adms#&gt; .\n@prefix esco:  &lt;http://data.europa.eu/esco/model#&gt; .\n@prefix rdf:   &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .\n@prefix org:   &lt;http://www.w3.org/ns/org#&gt; .\n@prefix iso-thes: &lt;http://purl.org/iso25964/skos-thes#&gt; .\n@prefix xsd:   &lt;http://www.w3.org/2001/XMLSchema#&gt; .\n@prefix skos:  &lt;http://www.w3.org/2004/02/skos/core#&gt; .\n@prefix rdfs:  &lt;http://www.w3.org/2000/01/rdf-schema#&gt; .\n@prefix prov:  &lt;http://www.w3.org/ns/prov#&gt; .\n@prefix foaf:  &lt;http://xmlns.com/foaf/0.1/&gt; .\n\n\n&lt;http://data.europa.eu/esco/skill/238343b1-7b51-42b3-a9ed-cf24d3a236e7&gt;\n        a                       skos:Concept , esco:MemberConcept , esco:Skill ;\n        esco:referenceLanguage  \"en\"^^xsd:language ;\n        esco:skillReuseLevel    &lt;http://data.europa.eu/esco/skill-reuse-level/transversal&gt; ;\n        esco:skillType          &lt;http://data.europa.eu/esco/skill-type/skill&gt; ;\n        dct:description         &lt;http://data.europa.eu/esco/node-literal/447a21ac-f4e0-41e1-a478-1b7cd4c29af8&gt; , &lt;http://data.europa.eu/esco/node-literal/d9f98a36-44fb-4318-bfd9-6ac6b520b034&gt; ;\n        iso-thes:status         \"released\" ;\n        skos:altLabel           \"reconocer las carencias en competencias digitales\"@es , \"bearnaí maidir le cumas digiteach a aithint\"@ga , \"identificere manglende digitale kundskaber\"@da , \"digitale vaardigheidskloven identificeren\"@nl , \"detectar las deficiencias en competencias digitales\"@es , \"behoeften aan digitale vaardigheden herkennen\"@nl , \"παροχή υποστήριξης για την αντιμετώπιση ελλείψεων όσον αφορά την ψηφιακή ικανότητα\"@el , \"detectar las lagunas en competencias digitales\"@es , \"tunnistaa digitaalisten taitojen puutteet\"@fi , \"Lücken bei den IKT-Kompetenzen erkennen\"@de ;\n        skos:broader            &lt;http://data.europa.eu/esco/skill/7e5147d1-60b1-4a68-804b-1f5cb0396b91&gt; ;\n        skos:broaderTransitive  &lt;http://data.europa.eu/esco/skill/7e5147d1-60b1-4a68-804b-1f5cb0396b91&gt; ;\n        skos:inScheme           &lt;http://data.europa.eu/esco/concept-scheme/skill-ict-groups&gt; ;\n        skos:prefLabel          \"digitale vaardigheidskloven herkennen\"@nl , \"εντοπισμός ελλείψεων όσον αφορά την ψηφιακή ικανότητα\"@el , [...] .\n\n</code></pre>\n\n<p>I have been reading a lot on the topic, but still I dont quite understand how I could convert this file to csv (or even JSON would do) with Java. So far I have been using the following script to extract all triples that exist in a graph and print them out in a console:</p>\n\n<pre><code>package semanticweb;\n\nimport org.apache.jena.query.Query;\nimport org.apache.jena.query.QueryExecution;\nimport org.apache.jena.query.QueryExecutionFactory;\nimport org.apache.jena.query.QueryFactory;\nimport org.apache.jena.query.QuerySolution;\nimport org.apache.jena.query.ResultSet;\nimport org.apache.jena.rdf.model.Model;\nimport org.apache.jena.rdf.model.ModelFactory;\n\npublic class Main {\n\n    public static void main(String[] args) {\n        // TODO Auto-generated method stub\n        getData();\n    }\n\n    static void getData(){\n\n        Model model = ModelFactory.createDefaultModel() ;\n        model.read(\"C:/Users/andri/eclipse-workspace/semanticweb/ict_skills_collection.ttl\");\n\n        String queryString = \"PREFIX skos-xl: &lt;http://www.w3.org/2008/05/skos-xl#&gt;\" +\n                \"PREFIX dct:   &lt;http://purl.org/dc/terms/&gt;\" +\n                \"PREFIX adms:  &lt;http://www.w3.org/ns/adms#&gt;\" +\n                \"PREFIX esco:  &lt;http://data.europa.eu/esco/model#&gt;\" +\n                \"PREFIX rdf:   &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;\" +\n                \"PREFIX org:   &lt;http://www.w3.org/ns/org#&gt;\"+\n                \"PREFIX iso-thes: &lt;http://purl.org/iso25964/skos-thes#&gt;\"+\n                \"PREFIX xsd:   &lt;http://www.w3.org/2001/XMLSchema#&gt;\" +\n                \"PREFIX skos:  &lt;http://www.w3.org/2004/02/skos/core#&gt;\" +\n                \"PREFIX rdfs:  &lt;http://www.w3.org/2000/01/rdf-schema#&gt;\" +\n                \"PREFIX prov:  &lt;http://www.w3.org/ns/prov#&gt;\"+\n                \"PREFIX foaf:  &lt;http://xmlns.com/foaf/0.1/&gt;\" +  \n                \"SELECT *\"+\n                 \"WHERE { ?s ?p ?o }\"; \n\n\n        Query query = QueryFactory.create(queryString);\n        QueryExecution qexec = QueryExecutionFactory.create(query, model);\n\n        try {\n\n         ResultSet results = qexec.execSelect();\n         while(results.hasNext()) {\n             QuerySolution qsol = results.nextSolution();\n             System.out.println(qsol.toString());\n         }\n        }\n            finally {\n                qexec.close();\n            }   \n\n\n    }\n\n}\n</code></pre>\n\n<p>The console output looks somewhat like this:</p>\n\n<pre><code>( ?p = &lt;http://www.w3.org/2004/02/skos/core#prefLabel&gt; ) ( ?o = \"Defizite bei der digitalen Kompetenz ermitteln\"@de ) ( ?s = &lt;http://data.europa.eu/esco/skill/238343b1-7b51-42b3-a9ed-cf24d3a236e7&gt; ) -&gt; [Root]\n( ?p = &lt;http://www.w3.org/2004/02/skos/core#prefLabel&gt; ) ( ?o = \"identifikovat nedostatky v digitalnych kompetenciach\"@sk ) ( ?s = &lt;http://data.europa.eu/esco/skill/238343b1-7b51-42b3-a9ed-cf24d3a236e7&gt; ) -&gt; [Root]\n( ?p = &lt;http://www.w3.org/2004/02/skos/core#prefLabel&gt; ) ( ?o = \"identificar lacunas nas competencias digitais\"@pt ) ( ?s = &lt;http://data.europa.eu/esco/skill/238343b1-7b51-42b3-a9ed-cf24d3a236e7&gt; ) -&gt; [Root]\n</code></pre>\n\n<p>Does anyone know how I could proceed in converting this triple format to csv? Do I need to understand what these triples represent exactly in order to do this? I appreciate any help you can provide</p>\n"},{"tags":["rdf","semantic-web","linked-data"],"owner":{"account_id":12317919,"reputation":309,"user_id":8987824,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/5c53e30157dbbd73cd6067ffe1f038fe?s=256&d=identicon&r=PG&f=1","display_name":"alordlord","link":"https://stackoverflow.com/users/8987824/alordlord"},"is_answered":true,"view_count":115,"accepted_answer_id":57282198,"answer_count":1,"score":0,"last_activity_date":1564538645,"creation_date":1564490548,"question_id":57271972,"body_markdown":"I have been working with Linked-Data lately and it has been causing me a headache. Although I have read a lot of pages on the RDF format I dont understand entirely if it is used to hold data, e.g. for a database, or if it is something like a way to model how data interconnect with each other. I apologize if my question is obvious, but I havent been able to clarify this myself.\r\n\r\n**An example of a document I came across lately:**\r\n\r\nThe Europian Commision has about 13485 Skills and Competences listed in their database as described here:  https://ec.europa.eu/esco/portal/skill\r\n\r\nHowever when I download a document with their Skills&amp;Competences from this source https://ec.europa.eu/esco/portal/download I get an RDF document, which doesnt seem to hold 13485 entries. This is how the document looks like:\r\n\r\n```\r\n@prefix skos-xl: &lt;http://www.w3.org/2008/05/skos-xl#&gt; .\r\n@prefix dct:   &lt;http://purl.org/dc/terms/&gt; .\r\n@prefix adms:  &lt;http://www.w3.org/ns/adms#&gt; .\r\n@prefix esco:  &lt;http://data.europa.eu/esco/model#&gt; .\r\n@prefix rdf:   &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .\r\n@prefix org:   &lt;http://www.w3.org/ns/org#&gt; .\r\n@prefix iso-thes: &lt;http://purl.org/iso25964/skos-thes#&gt; .\r\n@prefix xsd:   &lt;http://www.w3.org/2001/XMLSchema#&gt; .\r\n@prefix skos:  &lt;http://www.w3.org/2004/02/skos/core#&gt; .\r\n@prefix rdfs:  &lt;http://www.w3.org/2000/01/rdf-schema#&gt; .\r\n@prefix prov:  &lt;http://www.w3.org/ns/prov#&gt; .\r\n@prefix foaf:  &lt;http://xmlns.com/foaf/0.1/&gt; .\r\n\r\n&lt;http://data.europa.eu/esco/skill/1a4cc54f-1e53-442b-a6d2-1682dc8ef8f9&gt;\r\n        a                       esco:Skill , skos:Concept , esco:MemberConcept ;\r\n        esco:referenceLanguage  &quot;en&quot;^^xsd:language ;\r\n        esco:skillReuseLevel    &lt;http://data.europa.eu/esco/skill-reuse-level/transversal&gt; ;\r\n        esco:skillType          &lt;http://data.europa.eu/esco/skill-type/skill&gt; ;\r\n        dct:description         &lt;http://data.europa.eu/esco/node-literal/7d44a65e-ca7d-4631-a5ce-b33223f383ed&gt; , &lt;http://data.europa.eu/esco/node-literal/059327cb-5ded-4a22-89c5-f0950a69d9d0&gt; ;\r\n        iso-thes:status         &quot;released&quot; ;\r\n        skos:altLabel           &quot;digitale technologie&#235;n inzetten voor innovatie&quot;@nl , &quot;tw&#243;rcze wykorzystanie technologii cyfrowych&quot;@pl , &quot;innovatief gebruikmaken van digitale technologie&#235;n&quot;@nl ;\r\n        skos:broader            &lt;http://data.europa.eu/esco/skill/7e5147d1-60b1-4a68-804b-1f5cb0396b91&gt; ;\r\n        skos:broaderTransitive  &lt;http://data.europa.eu/esco/skill/7e5147d1-60b1-4a68-804b-1f5cb0396b91&gt; ;\r\n        skos:inScheme           &lt;http://data.europa.eu/esco/concept-scheme/skill-ict-groups&gt; ;\r\n        skos:prefLabel          &quot;notar stafr&#230;na t&#230;kni &#225; hugvitsamlegan h&#225;tt&quot;@is , &quot;k&#228;ytt&#228;&#228; digitaaliteknologiaa luovasti&quot;@fi , &quot;využ&#237;vat digit&#225;ln&#237; technologie kreativně&quot;@cs , &quot;kreativno se koristiti digitalnim tehnologijama&quot;@hr , &quot;utilizare creativă a tehnologiilor digitale&quot;@ro , &quot;bruke digitale teknologier kreativt&quot;@no , &quot;anv&#228;nda digital teknik p&#229; ett kreativt s&#228;tt&quot;@sv , &quot;utilizar de forma criativa as tecnologias digitais&quot;@pt , &quot;radoši izmantot digitālās tehnoloģijas&quot;@lv , &quot;kreatywne wykorzystanie technologii cyfrowych&quot;@pl , &quot;creatief gebruikmaken van digitale technologie&#235;n&quot;@nl , &quot;kūrybiškai naudoti skaitmenines technologijas&quot;@lt , &quot;digitale Technologien kreativ einsetzen&quot;@de , &quot;kreativno uporabljati digitalne tehnologije&quot;@sl , &quot;utilizar creativamente las tecnolog&#237;as digitales&quot;@es , &quot;digitaaltehnoloogiat loovalt kasutama&quot;@et , &quot;anvende digitale teknologier kreativt&quot;@da , &quot;يستخدم بشكل خلاق التكنولوجيات الرقمية&quot;@ar , &quot;teicneola&#237;ochta&#237; digiteacha a &#250;s&#225;id ar dh&#243;igh chruthaitheach&quot;@ga , &quot;δημιουργική χρήση ψηφιακών τεχνολογιών&quot;@el , &quot;usare le tecnologie digitali in modo creativo&quot;@it , &quot;kreat&#237;van alkalmazza a digit&#225;lis technol&#243;gi&#225;kat&quot;@hu , &quot;utiliser des technologies num&#233;riques de fa&#231;on cr&#233;ative&quot;@fr , &quot;tvorivo využ&#237;vať digit&#225;lne technol&#243;gie&quot;@sk , &quot;creatively use digital technologies&quot;@en , &quot;creatively use digital technologies&quot;@en-us , &quot;użu kreattiv tat-teknoloġiji diġitali&quot;@mt , &quot;творческо използване на цифровите технологии&quot;@bg .\r\n\r\n&lt;http://data.europa.eu/esco/node-literal/60953fa2-4a4c-45de-b64f-10c475e5674e&gt;\r\n        a                 esco:NodeLiteral ;\r\n        esco:language     &quot;en-us&quot;^^xsd:language ;\r\n        esco:nodeLiteral  &quot;Apply behavioral norms and know-how while using digital technologies and interacting in digital environments. Adapt communication strategies to the specific audience and be aware of cultural and generational diversity in digital environments.&quot; .\r\n\r\n&lt;http://data.europa.eu/esco/node-literal/02eb4966-46f0-4311-af66-2bbab192c978&gt;\r\n        a                 esco:NodeLiteral ;\r\n        esco:language     &quot;en&quot; ;\r\n        esco:nodeLiteral  &quot;Articulate information needs, search for data, information and content in digital environments, access them and navigate between them. Create and update personal search strategies.&quot; .\r\n\r\n&lt;http://data.europa.eu/esco/skill/1d6c7de4-350e-4868-a47b-333b4b0d9650&gt;\r\n        a                       esco:Skill , esco:MemberConcept , skos:Concept ;\r\n        esco:referenceLanguage  &quot;en&quot;^^xsd:language ;\r\n        esco:skillReuseLevel    &lt;http://data.europa.eu/esco/skill-reuse-level/transversal&gt; ;\r\n        esco:skillType          &lt;http://data.europa.eu/esco/skill-type/skill&gt; ;\r\n        dct:description         &lt;http://data.europa.eu/esco/node-literal/065e18f8-df44-49a9-a153-25eef949fb07&gt; , &lt;http://data.europa.eu/esco/node-literal/4a925ea1-89a8-4819-94c6-0f2c49e7212e&gt; ;\r\n        iso-thes:status         &quot;released&quot; ;\r\n        skos:altLabel           &quot;gegevens, informatie en digitale content evalueren&quot;@nl , &quot;gegevens, informatie en digitale inhoud beoordelen&quot;@nl , &quot;analizar datos, informaci&#243;n y contenido digitales&quot;@es , &quot;evaluar datos, informaci&#243;n y contenidos digitales&quot;@es , &quot;izvērtēt datus, informāciju un digitālo saturu&quot;@lv , &quot;gegevens, informatie en digitale content beoordelen&quot;@nl , &quot;examinar datos, informaci&#243;n y contenido digitales&quot;@es , &quot;analizează date, informații și conținut digital&quot;@ro , &quot;sonra&#237;, faisn&#233;is agus &#225;bhar digiteach a mheas&quot;@ga , &quot;interpretează date, informații și conținut digital&quot;@ro , &quot;evaluar datos, informaci&#243;n y contenido electr&#243;nicos&quot;@es ;\r\n        skos:broader            &lt;http://data.europa.eu/esco/skill/629685b8-5f9e-4522-8cff-b3e2c4ec625a&gt; ;\r\n        skos:broaderTransitive  &lt;http://data.europa.eu/esco/skill/629685b8-5f9e-4522-8cff-b3e2c4ec625a&gt; ;\r\n        skos:inScheme           &lt;http://data.europa.eu/esco/concept-scheme/skill-ict-groups&gt; ;\r\n        skos:prefLabel          &quot;evalwazzjoni tad-dejta, tal-informazzjoni u tal-kontenut diġitali&quot;@mt , &quot;evaluate data, information and digital content&quot;@en , &quot;evaluate data, information and digital content&quot;@en-us , &quot;Daten, Informationen und digitale Inhalte bewerten&quot;@de , &quot;αξιολόγηση δεδομένων, πληροφοριών και ψηφιακού περιεχομένου&quot;@el , &quot;evaluează date, informații și conținut digital&quot;@ro , &quot;presojati podatke, informacije in digitalne vsebine&quot;@sl , &quot;analiza danych, informacji i treści cyfrowych&quot;@pl , &quot;оценяване на данни, информация и цифрово съдържание&quot;@bg , &quot;يحدد البيانات والمعلومات والمحتوى الرقمي&quot;@ar , &quot;sonra&#237;, faisn&#233;is agus inneachar digiteach a mheas&quot;@ga , &quot;bed&#246;ma data, information och digitalt inneh&#229;ll&quot;@sv , &quot;gegevens, informatie en digitale inhoud evalueren&quot;@nl , &quot;andmete, teabe ja digitaalset sisu hindama&quot;@et , &quot;valutare dati, informazioni e contenuti digitali&quot;@it , &quot;avaliar dados, informa&#231;&#245;es e conte&#250;dos digitais&quot;@pt , &quot;evaluar datos, informaci&#243;n y contenido digitales&quot;@es , &quot;vyhodnocovat &#250;daje, informace a digit&#225;ln&#237; obsah&quot;@cs , &quot;vyhodnocovať &#250;daje, inform&#225;cie a digit&#225;lny obsah&quot;@sk , &quot;adatokat, inform&#225;ci&#243;kat &#233;s digit&#225;lis tartalmakat &#233;rt&#233;kel&quot;@hu , &quot;arvioida dataa, tietoa ja digitaalista sis&#228;lt&#246;&#228;&quot;@fi , &quot;evaluere data, informasjon og digitalt innhold&quot;@no , &quot;ocjenjivati podatke, informacije i digitalni sadržaj&quot;@hr , &quot;metur g&#246;gn, uppl&#253;singar og stafr&#230;nt inntak&quot;@is , &quot;&#233;valuer des donn&#233;es, des informations et des contenus num&#233;riques&quot;@fr , &quot;novērtēt datus, informāciju un digitālo saturu&quot;@lv , &quot;evaluere data, oplysninger og digitalt indhold&quot;@da , &quot;vertinti duomenis, informaciją ir skaitmeninį turinį&quot;@lt . [...]\r\n```\r\n\r\nI understand that the document is relatively large and that is why I couldnt fit it all here, but it holds predicators and objects for approximately 80 subjects. Does anyone understand what the purpose of this document is? I appreciate any help you can provide.\r\n","link":"https://stackoverflow.com/questions/57271972/does-rdf-store-data-or-does-it-describe-a-data-model","title":"Does RDF store data or does it describe a data model?","body":"<p>I have been working with Linked-Data lately and it has been causing me a headache. Although I have read a lot of pages on the RDF format I dont understand entirely if it is used to hold data, e.g. for a database, or if it is something like a way to model how data interconnect with each other. I apologize if my question is obvious, but I havent been able to clarify this myself.</p>\n\n<p><strong>An example of a document I came across lately:</strong></p>\n\n<p>The Europian Commision has about 13485 Skills and Competences listed in their database as described here:  <a href=\"https://ec.europa.eu/esco/portal/skill\" rel=\"nofollow noreferrer\">https://ec.europa.eu/esco/portal/skill</a></p>\n\n<p>However when I download a document with their Skills&amp;Competences from this source <a href=\"https://ec.europa.eu/esco/portal/download\" rel=\"nofollow noreferrer\">https://ec.europa.eu/esco/portal/download</a> I get an RDF document, which doesnt seem to hold 13485 entries. This is how the document looks like:</p>\n\n<pre><code>@prefix skos-xl: &lt;http://www.w3.org/2008/05/skos-xl#&gt; .\n@prefix dct:   &lt;http://purl.org/dc/terms/&gt; .\n@prefix adms:  &lt;http://www.w3.org/ns/adms#&gt; .\n@prefix esco:  &lt;http://data.europa.eu/esco/model#&gt; .\n@prefix rdf:   &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .\n@prefix org:   &lt;http://www.w3.org/ns/org#&gt; .\n@prefix iso-thes: &lt;http://purl.org/iso25964/skos-thes#&gt; .\n@prefix xsd:   &lt;http://www.w3.org/2001/XMLSchema#&gt; .\n@prefix skos:  &lt;http://www.w3.org/2004/02/skos/core#&gt; .\n@prefix rdfs:  &lt;http://www.w3.org/2000/01/rdf-schema#&gt; .\n@prefix prov:  &lt;http://www.w3.org/ns/prov#&gt; .\n@prefix foaf:  &lt;http://xmlns.com/foaf/0.1/&gt; .\n\n&lt;http://data.europa.eu/esco/skill/1a4cc54f-1e53-442b-a6d2-1682dc8ef8f9&gt;\n        a                       esco:Skill , skos:Concept , esco:MemberConcept ;\n        esco:referenceLanguage  \"en\"^^xsd:language ;\n        esco:skillReuseLevel    &lt;http://data.europa.eu/esco/skill-reuse-level/transversal&gt; ;\n        esco:skillType          &lt;http://data.europa.eu/esco/skill-type/skill&gt; ;\n        dct:description         &lt;http://data.europa.eu/esco/node-literal/7d44a65e-ca7d-4631-a5ce-b33223f383ed&gt; , &lt;http://data.europa.eu/esco/node-literal/059327cb-5ded-4a22-89c5-f0950a69d9d0&gt; ;\n        iso-thes:status         \"released\" ;\n        skos:altLabel           \"digitale technologieën inzetten voor innovatie\"@nl , \"twórcze wykorzystanie technologii cyfrowych\"@pl , \"innovatief gebruikmaken van digitale technologieën\"@nl ;\n        skos:broader            &lt;http://data.europa.eu/esco/skill/7e5147d1-60b1-4a68-804b-1f5cb0396b91&gt; ;\n        skos:broaderTransitive  &lt;http://data.europa.eu/esco/skill/7e5147d1-60b1-4a68-804b-1f5cb0396b91&gt; ;\n        skos:inScheme           &lt;http://data.europa.eu/esco/concept-scheme/skill-ict-groups&gt; ;\n        skos:prefLabel          \"notar stafræna tækni á hugvitsamlegan hátt\"@is , \"käyttää digitaaliteknologiaa luovasti\"@fi , \"využívat digitální technologie kreativně\"@cs , \"kreativno se koristiti digitalnim tehnologijama\"@hr , \"utilizare creativă a tehnologiilor digitale\"@ro , \"bruke digitale teknologier kreativt\"@no , \"använda digital teknik på ett kreativt sätt\"@sv , \"utilizar de forma criativa as tecnologias digitais\"@pt , \"radoši izmantot digitālās tehnoloģijas\"@lv , \"kreatywne wykorzystanie technologii cyfrowych\"@pl , \"creatief gebruikmaken van digitale technologieën\"@nl , \"kūrybiškai naudoti skaitmenines technologijas\"@lt , \"digitale Technologien kreativ einsetzen\"@de , \"kreativno uporabljati digitalne tehnologije\"@sl , \"utilizar creativamente las tecnologías digitales\"@es , \"digitaaltehnoloogiat loovalt kasutama\"@et , \"anvende digitale teknologier kreativt\"@da , \"يستخدم بشكل خلاق التكنولوجيات الرقمية\"@ar , \"teicneolaíochtaí digiteacha a úsáid ar dhóigh chruthaitheach\"@ga , \"δημιουργική χρήση ψηφιακών τεχνολογιών\"@el , \"usare le tecnologie digitali in modo creativo\"@it , \"kreatívan alkalmazza a digitális technológiákat\"@hu , \"utiliser des technologies numériques de façon créative\"@fr , \"tvorivo využívať digitálne technológie\"@sk , \"creatively use digital technologies\"@en , \"creatively use digital technologies\"@en-us , \"użu kreattiv tat-teknoloġiji diġitali\"@mt , \"творческо използване на цифровите технологии\"@bg .\n\n&lt;http://data.europa.eu/esco/node-literal/60953fa2-4a4c-45de-b64f-10c475e5674e&gt;\n        a                 esco:NodeLiteral ;\n        esco:language     \"en-us\"^^xsd:language ;\n        esco:nodeLiteral  \"Apply behavioral norms and know-how while using digital technologies and interacting in digital environments. Adapt communication strategies to the specific audience and be aware of cultural and generational diversity in digital environments.\" .\n\n&lt;http://data.europa.eu/esco/node-literal/02eb4966-46f0-4311-af66-2bbab192c978&gt;\n        a                 esco:NodeLiteral ;\n        esco:language     \"en\" ;\n        esco:nodeLiteral  \"Articulate information needs, search for data, information and content in digital environments, access them and navigate between them. Create and update personal search strategies.\" .\n\n&lt;http://data.europa.eu/esco/skill/1d6c7de4-350e-4868-a47b-333b4b0d9650&gt;\n        a                       esco:Skill , esco:MemberConcept , skos:Concept ;\n        esco:referenceLanguage  \"en\"^^xsd:language ;\n        esco:skillReuseLevel    &lt;http://data.europa.eu/esco/skill-reuse-level/transversal&gt; ;\n        esco:skillType          &lt;http://data.europa.eu/esco/skill-type/skill&gt; ;\n        dct:description         &lt;http://data.europa.eu/esco/node-literal/065e18f8-df44-49a9-a153-25eef949fb07&gt; , &lt;http://data.europa.eu/esco/node-literal/4a925ea1-89a8-4819-94c6-0f2c49e7212e&gt; ;\n        iso-thes:status         \"released\" ;\n        skos:altLabel           \"gegevens, informatie en digitale content evalueren\"@nl , \"gegevens, informatie en digitale inhoud beoordelen\"@nl , \"analizar datos, información y contenido digitales\"@es , \"evaluar datos, información y contenidos digitales\"@es , \"izvērtēt datus, informāciju un digitālo saturu\"@lv , \"gegevens, informatie en digitale content beoordelen\"@nl , \"examinar datos, información y contenido digitales\"@es , \"analizează date, informații și conținut digital\"@ro , \"sonraí, faisnéis agus ábhar digiteach a mheas\"@ga , \"interpretează date, informații și conținut digital\"@ro , \"evaluar datos, información y contenido electrónicos\"@es ;\n        skos:broader            &lt;http://data.europa.eu/esco/skill/629685b8-5f9e-4522-8cff-b3e2c4ec625a&gt; ;\n        skos:broaderTransitive  &lt;http://data.europa.eu/esco/skill/629685b8-5f9e-4522-8cff-b3e2c4ec625a&gt; ;\n        skos:inScheme           &lt;http://data.europa.eu/esco/concept-scheme/skill-ict-groups&gt; ;\n        skos:prefLabel          \"evalwazzjoni tad-dejta, tal-informazzjoni u tal-kontenut diġitali\"@mt , \"evaluate data, information and digital content\"@en , \"evaluate data, information and digital content\"@en-us , \"Daten, Informationen und digitale Inhalte bewerten\"@de , \"αξιολόγηση δεδομένων, πληροφοριών και ψηφιακού περιεχομένου\"@el , \"evaluează date, informații și conținut digital\"@ro , \"presojati podatke, informacije in digitalne vsebine\"@sl , \"analiza danych, informacji i treści cyfrowych\"@pl , \"оценяване на данни, информация и цифрово съдържание\"@bg , \"يحدد البيانات والمعلومات والمحتوى الرقمي\"@ar , \"sonraí, faisnéis agus inneachar digiteach a mheas\"@ga , \"bedöma data, information och digitalt innehåll\"@sv , \"gegevens, informatie en digitale inhoud evalueren\"@nl , \"andmete, teabe ja digitaalset sisu hindama\"@et , \"valutare dati, informazioni e contenuti digitali\"@it , \"avaliar dados, informações e conteúdos digitais\"@pt , \"evaluar datos, información y contenido digitales\"@es , \"vyhodnocovat údaje, informace a digitální obsah\"@cs , \"vyhodnocovať údaje, informácie a digitálny obsah\"@sk , \"adatokat, információkat és digitális tartalmakat értékel\"@hu , \"arvioida dataa, tietoa ja digitaalista sisältöä\"@fi , \"evaluere data, informasjon og digitalt innhold\"@no , \"ocjenjivati podatke, informacije i digitalni sadržaj\"@hr , \"metur gögn, upplýsingar og stafrænt inntak\"@is , \"évaluer des données, des informations et des contenus numériques\"@fr , \"novērtēt datus, informāciju un digitālo saturu\"@lv , \"evaluere data, oplysninger og digitalt indhold\"@da , \"vertinti duomenis, informaciją ir skaitmeninį turinį\"@lt . [...]\n</code></pre>\n\n<p>I understand that the document is relatively large and that is why I couldnt fit it all here, but it holds predicators and objects for approximately 80 subjects. Does anyone understand what the purpose of this document is? I appreciate any help you can provide.</p>\n"},{"tags":["python","web-scraping","scrapy","web-crawler"],"owner":{"account_id":12317919,"reputation":309,"user_id":8987824,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/5c53e30157dbbd73cd6067ffe1f038fe?s=256&d=identicon&r=PG&f=1","display_name":"alordlord","link":"https://stackoverflow.com/users/8987824/alordlord"},"is_answered":true,"view_count":133,"accepted_answer_id":57186875,"answer_count":1,"score":1,"last_activity_date":1563983512,"creation_date":1563981380,"question_id":57186226,"body_markdown":"I am using `scrapy` in order to extract content from a website. This is part of the websites element structure:\r\n\r\n\r\n\r\n[![enter image description here][1]][1]\r\n  [1]: https://i.stack.imgur.com/0eKfj.png\r\n\r\nI want to print on the console all the content that is contained in the `single-main-content` class and therefore I have written the following script:\r\n\r\n\r\n```\r\nimport scrapy\r\n\r\nclass SkillsSpider(scrapy.Spider):\r\n    name = &#39;skills&#39;\r\n\r\n    start_urls = [\r\n        &#39;http://data.europa.eu/esco/skill/1a4cc54f-1e53-442b-a6d2-1682dc8ef8f9&#39;\r\n    ]\r\n\r\n    def parse(self, response):\r\n        for items in response.css(&#39;single-main-content&#39;):\r\n            text = items.css(&#39;single-main-content&#39;).extract()\r\n            print(text)\r\n```\r\n\r\nDespite that, nothing related to it is printed on my console. Can someone please help me understand what I am doing wrong? I appreciate any help ","link":"https://stackoverflow.com/questions/57186226/how-can-i-print-on-the-console-all-the-content-of-a-specific-class-from-a-websit","title":"How can I print on the console all the content of a specific class from a website I am crawling in?","body":"<p>I am using <code>scrapy</code> in order to extract content from a website. This is part of the websites element structure:</p>\n\n<p><a href=\"https://i.stack.imgur.com/0eKfj.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/0eKfj.png\" alt=\"enter image description here\"></a>\nI want to print on the console all the content that is contained in the <code>single-main-content</code> class and therefore I have written the following script:</p>\n\n<pre><code>import scrapy\n\nclass SkillsSpider(scrapy.Spider):\n    name = 'skills'\n\n    start_urls = [\n        'http://data.europa.eu/esco/skill/1a4cc54f-1e53-442b-a6d2-1682dc8ef8f9'\n    ]\n\n    def parse(self, response):\n        for items in response.css('single-main-content'):\n            text = items.css('single-main-content').extract()\n            print(text)\n</code></pre>\n\n<p>Despite that, nothing related to it is printed on my console. Can someone please help me understand what I am doing wrong? I appreciate any help </p>\n"},{"tags":["python","python-3.x","python-requests"],"owner":{"account_id":3711737,"reputation":1987,"user_id":3088897,"user_type":"registered","accept_rate":69,"profile_image":"https://i.stack.imgur.com/nLj69.jpg?s=256&g=1","display_name":"Minisha","link":"https://stackoverflow.com/users/3088897/minisha"},"is_answered":true,"view_count":306,"answer_count":1,"score":-1,"last_activity_date":1528357207,"creation_date":1528353471,"last_edit_date":1528355012,"question_id":50734464,"body_markdown":"When I tried to make request with python requests library like below. I am getting the below exception \r\n\r\n    def get_request(url):\r\n        return requests.get(url).json()\r\n\r\nException\r\n\r\n        palo:dataextractor minisha$ python escoskill.py \r\n    Traceback (most recent call last):\r\n      File &quot;escoskill.py&quot;, line 62, in &lt;module&gt;\r\n        print(response.json())\r\n    UnicodeEncodeError: &#39;ascii&#39; codec can&#39;t encode character &#39;\\xe4&#39; in position 277: ordinal not in range(128)\r\n\r\n\r\nHowever, the same piece of code works for some request and not for all. For the below url, it doesn&#39;t work. \r\n\r\n    https://ec.europa.eu/esco/api/resource/concept?uri=http://data.europa.eu/esco/isco/C2&amp;language=en\r\n      \r\n\r\nUrl that works\r\n\r\n    https://ec.europa.eu/esco/api/resource/taxonomy?uri=http://data.europa.eu/esco/concept-scheme/isco&amp;language=en\r\n\r\n","link":"https://stackoverflow.com/questions/50734464/unicodepython-3-encodeerror-ascii-codec-cant-encode-character-xe4-in-pos","title":"UnicodePython 3: EncodeError: &#39;ascii&#39; codec can&#39;t encode character &#39;\\xe4&#39; in position 277: ordinal not in range(128)","body":"<p>When I tried to make request with python requests library like below. I am getting the below exception </p>\n\n<pre><code>def get_request(url):\n    return requests.get(url).json()\n</code></pre>\n\n<p>Exception</p>\n\n<pre><code>    palo:dataextractor minisha$ python escoskill.py \nTraceback (most recent call last):\n  File \"escoskill.py\", line 62, in &lt;module&gt;\n    print(response.json())\nUnicodeEncodeError: 'ascii' codec can't encode character '\\xe4' in position 277: ordinal not in range(128)\n</code></pre>\n\n<p>However, the same piece of code works for some request and not for all. For the below url, it doesn't work. </p>\n\n<pre><code>https://ec.europa.eu/esco/api/resource/concept?uri=http://data.europa.eu/esco/isco/C2&amp;language=en\n</code></pre>\n\n<p>Url that works</p>\n\n<pre><code>https://ec.europa.eu/esco/api/resource/taxonomy?uri=http://data.europa.eu/esco/concept-scheme/isco&amp;language=en\n</code></pre>\n"},{"tags":["json","xml","file","graph","turtle-rdf"],"owner":{"account_id":3953311,"reputation":1877,"user_id":3262787,"user_type":"registered","accept_rate":60,"profile_image":"https://www.gravatar.com/avatar/09530ed6bcc0b7e3331a20d3bb5c0ddc?s=256&d=identicon&r=PG&f=1","display_name":"DaveTheAl","link":"https://stackoverflow.com/users/3262787/davetheal"},"is_answered":true,"view_count":20513,"accepted_answer_id":49959072,"answer_count":2,"score":11,"last_activity_date":1524336079,"creation_date":1524319241,"last_edit_date":1524319899,"question_id":49956557,"body_markdown":"I have a file which has a structure, but I don&#39;t know what format it is, nor how to parse it. The file extension is ttl, but I have never encountered this before.\r\n\r\nSome lines from the file looks like this:\r\n\r\n    &lt;http://data.europa.eu/esco/label/790ff9ed-c43b-435c-b6b3-6a4a6e8e8326&gt;\r\n        a                   skosxl:Label ;\r\n        skosxl:literalForm  &quot;g&#233;rer des op&#233;rations d’all&#232;gement&quot;@fr .\r\n\r\n    &lt;http://data.europa.eu/esco/label/98570af6-b237-4cdd-b555-98fe3de26ef8&gt;\r\n        a                   skosxl:Label ;\r\n        esco:hasLabelRole   &lt;http://data.europa.eu/esco/label-role/neutral&gt; , &lt;http://data.europa.eu/esco/label-role/male&gt; , &lt;http://data.europa.eu/esco/label-role/female&gt; ;\r\n        skosxl:literalForm  &quot;particleboard machine technician&quot;@en .\r\n\r\n    &lt;http://data.europa.eu/esco/label/aaac5531-fc8d-40d5-bfb8-fc9ba741ac21&gt;\r\n        a                   skosxl:Label ;\r\n        esco:hasLabelRole   &quot;http://data.europa.eu/esco/label-role/female&quot; , &quot;http://data.europa.eu/esco/label-role/standard-female&quot; ;\r\n        skosxl:literalForm  &quot;pracovnice denn&#237; p&#233;če o děti&quot;@cs .\r\n\r\nAnd it goes on like this for 400 more MB. Additional attributes are added, for some, but not all nodes. \r\n\r\nIt reminds me of some form of XML, but I don&#39;t have much experience working with different formats. It also looks like something that can be modeles as a graph.\r\nDo you have any idea what data format it is, and how I could parse it in python?","link":"https://stackoverflow.com/questions/49956557/ttl-file-format-i-have-no-idea-what-this-is","title":"TTL file format - I have no idea what this is","body":"<p>I have a file which has a structure, but I don't know what format it is, nor how to parse it. The file extension is ttl, but I have never encountered this before.</p>\n\n<p>Some lines from the file looks like this:</p>\n\n<pre><code>&lt;http://data.europa.eu/esco/label/790ff9ed-c43b-435c-b6b3-6a4a6e8e8326&gt;\n    a                   skosxl:Label ;\n    skosxl:literalForm  \"gérer des opérations d’allègement\"@fr .\n\n&lt;http://data.europa.eu/esco/label/98570af6-b237-4cdd-b555-98fe3de26ef8&gt;\n    a                   skosxl:Label ;\n    esco:hasLabelRole   &lt;http://data.europa.eu/esco/label-role/neutral&gt; , &lt;http://data.europa.eu/esco/label-role/male&gt; , &lt;http://data.europa.eu/esco/label-role/female&gt; ;\n    skosxl:literalForm  \"particleboard machine technician\"@en .\n\n&lt;http://data.europa.eu/esco/label/aaac5531-fc8d-40d5-bfb8-fc9ba741ac21&gt;\n    a                   skosxl:Label ;\n    esco:hasLabelRole   \"http://data.europa.eu/esco/label-role/female\" , \"http://data.europa.eu/esco/label-role/standard-female\" ;\n    skosxl:literalForm  \"pracovnice denní péče o děti\"@cs .\n</code></pre>\n\n<p>And it goes on like this for 400 more MB. Additional attributes are added, for some, but not all nodes. </p>\n\n<p>It reminds me of some form of XML, but I don't have much experience working with different formats. It also looks like something that can be modeles as a graph.\nDo you have any idea what data format it is, and how I could parse it in python?</p>\n"},{"tags":["python","regex"],"owner":{"account_id":2586083,"reputation":2429,"user_id":2241766,"user_type":"registered","accept_rate":48,"profile_image":"https://www.gravatar.com/avatar/c9cc08f5ea5bcb801919ff650648eec3?s=256&d=identicon&r=PG","display_name":"lenhhoxung","link":"https://stackoverflow.com/users/2241766/lenhhoxung"},"is_answered":true,"view_count":157,"closed_date":1486927139,"accepted_answer_id":42189684,"answer_count":1,"score":1,"last_activity_date":1486914929,"creation_date":1486914224,"question_id":42189614,"body_markdown":"I&#39;m trying to parse my csv file using Python. Each row has four element separating by commas. Eeach element is a string, but it may contain commas as well. In case an element contains a comma, that element is double quoted. Following examples show two different cases with and without quotes:\r\n\r\n    http://data.europa.eu/esco/skill/CTC_43028,&quot;use data extraction, transformation and loading tools&quot;,&quot;ETL|extract, transform, load&quot;,&quot;&lt;div&gt;Integrate information from multiple applications, created and maintained by various organisations, into one consistent and transparent data structure.&lt;/div&gt;&quot;\r\n    http://data.europa.eu/esco/skill/SCG.TS.1.4.m.2,support company plan,follow industry guidelines|follow organisation&#39;s vision|monitor policy implementation|support company mission,&lt;div&gt;Act within one&amp;#39;s work role to advance the goals and vision of the organisation.&lt;/div&gt;\r\n\r\nWhat I want is to split each row into four elements.\r\nI&#39;ve tried with split function of Python, but not successful. I suppose I&#39;ll have to use regular expression, but I&#39;m not familiar with it.\r\nCould you please give some helps? \r\nMany thanks.","link":"https://stackoverflow.com/questions/42189614/split-string-with-condition","closed_reason":"Duplicate","title":"split string with condition","body":"<p>I'm trying to parse my csv file using Python. Each row has four element separating by commas. Eeach element is a string, but it may contain commas as well. In case an element contains a comma, that element is double quoted. Following examples show two different cases with and without quotes:</p>\n\n<pre><code>http://data.europa.eu/esco/skill/CTC_43028,\"use data extraction, transformation and loading tools\",\"ETL|extract, transform, load\",\"&lt;div&gt;Integrate information from multiple applications, created and maintained by various organisations, into one consistent and transparent data structure.&lt;/div&gt;\"\nhttp://data.europa.eu/esco/skill/SCG.TS.1.4.m.2,support company plan,follow industry guidelines|follow organisation's vision|monitor policy implementation|support company mission,&lt;div&gt;Act within one&amp;#39;s work role to advance the goals and vision of the organisation.&lt;/div&gt;\n</code></pre>\n\n<p>What I want is to split each row into four elements.\nI've tried with split function of Python, but not successful. I suppose I'll have to use regular expression, but I'm not familiar with it.\nCould you please give some helps? \nMany thanks.</p>\n"},{"tags":["database","sparql","rdf"],"owner":{"account_id":2048724,"reputation":453,"user_id":1828195,"user_type":"registered","accept_rate":100,"profile_image":"https://www.gravatar.com/avatar/51ecb7c63a72b03a272f285a5ee2daff?s=256&d=identicon&r=PG","display_name":"Valtteri","link":"https://stackoverflow.com/users/1828195/valtteri"},"is_answered":true,"view_count":4281,"accepted_answer_id":36207179,"answer_count":2,"score":6,"last_activity_date":1458843160,"creation_date":1458745371,"last_edit_date":1458772360,"question_id":36181713,"body_markdown":"I am learning basics of SPARQL with recent RDF-database released by the Finnish Ministry of Justice. It contains Finnish law data.\r\n\r\nThere are statutes, which have versions, which have a date and topics. I want to get the most recent versions that have a &quot;gun&quot; topic. So, I wrote this:\r\n\r\n    PREFIX sfl: &lt;http://data.finlex.fi/schema/sfl/&gt;\r\n    PREFIX eli: &lt;http://data.europa.eu/eli/ontology#&gt;\r\n    PREFIX skos: &lt;http://www.w3.org/2004/02/skos/core#&gt;\r\n    PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;\r\n\r\n    SELECT ?stat ?vers ?dv \r\n    WHERE { \r\n       ?stat rdf:type sfl:Statute .\r\n       ?stat sfl:hasVersion ?vers .\r\n       ?vers eli:version_date ?dv .\r\n       ?vers eli:is_about ?top .\r\n  \t   ?top skos:prefLabel &quot;Ase&quot;@fi .\r\n\r\n     } ORDER BY DESC(?dv)\r\n\r\nThis returns four lines, with three statutes, one statute twice. This is because that statute has two versions, older and current. The two other statutes have only one version. \r\n\r\nHow do I get rid of the older version so I get only statutes with the most recent version? I tried using something like `(MAX(?dv) AS ?ndv)` and grouping by ?stat and ?vers, but this doesn&#39;t work, as there are four distinct versions.\r\n\r\nEDIT:\r\nLet me add a mock example of what happens.\r\n\r\nThe result of the original query looks like this:\r\n\r\n    stat | vers | dv\r\n     a   | abc  |  x\r\n     a   | cde  |  y(&lt;x)\r\n     b   | foo  |  z\r\n     c   | fot  |  u\r\n\r\nWe see that statute &quot;a&quot; has two versions, &quot;abc&quot; and &quot;cde&quot; and the dv of version &quot;abc&quot; is later that dv of version &quot;cde&quot;. The other two statutes &quot;b&quot; and &quot;c&quot; have only one version each, with dvs of &quot;z&quot; and &quot;u&quot;.\r\n\r\nThe property of having topic &quot;gun&quot; is a property of vers. All the versions returned have that topic.\r\n\r\nWhat I want to get is this:\r\n \r\n    stat | vers | dv\r\n     a   | abc  |  x\r\n     b   | foo  |  z\r\n     c   | fot  |  u\r\n\r\nIn other words, I wish to get, for each statute, only the version with the highest or latest dv value. \r\n\r\nPS. You are welcome to test this at http://yasgui.org/ Just type the query and you get the result.","link":"https://stackoverflow.com/questions/36181713/sparql-query-to-get-only-results-with-the-most-recent-date","title":"SPARQL query to get only results with the most recent date","body":"<p>I am learning basics of SPARQL with recent RDF-database released by the Finnish Ministry of Justice. It contains Finnish law data.</p>\n\n<p>There are statutes, which have versions, which have a date and topics. I want to get the most recent versions that have a \"gun\" topic. So, I wrote this:</p>\n\n<pre><code>PREFIX sfl: &lt;http://data.finlex.fi/schema/sfl/&gt;\nPREFIX eli: &lt;http://data.europa.eu/eli/ontology#&gt;\nPREFIX skos: &lt;http://www.w3.org/2004/02/skos/core#&gt;\nPREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;\n\nSELECT ?stat ?vers ?dv \nWHERE { \n   ?stat rdf:type sfl:Statute .\n   ?stat sfl:hasVersion ?vers .\n   ?vers eli:version_date ?dv .\n   ?vers eli:is_about ?top .\n   ?top skos:prefLabel \"Ase\"@fi .\n\n } ORDER BY DESC(?dv)\n</code></pre>\n\n<p>This returns four lines, with three statutes, one statute twice. This is because that statute has two versions, older and current. The two other statutes have only one version. </p>\n\n<p>How do I get rid of the older version so I get only statutes with the most recent version? I tried using something like <code>(MAX(?dv) AS ?ndv)</code> and grouping by ?stat and ?vers, but this doesn't work, as there are four distinct versions.</p>\n\n<p>EDIT:\nLet me add a mock example of what happens.</p>\n\n<p>The result of the original query looks like this:</p>\n\n<pre><code>stat | vers | dv\n a   | abc  |  x\n a   | cde  |  y(&lt;x)\n b   | foo  |  z\n c   | fot  |  u\n</code></pre>\n\n<p>We see that statute \"a\" has two versions, \"abc\" and \"cde\" and the dv of version \"abc\" is later that dv of version \"cde\". The other two statutes \"b\" and \"c\" have only one version each, with dvs of \"z\" and \"u\".</p>\n\n<p>The property of having topic \"gun\" is a property of vers. All the versions returned have that topic.</p>\n\n<p>What I want to get is this:</p>\n\n<pre><code>stat | vers | dv\n a   | abc  |  x\n b   | foo  |  z\n c   | fot  |  u\n</code></pre>\n\n<p>In other words, I wish to get, for each statute, only the version with the highest or latest dv value. </p>\n\n<p>PS. You are welcome to test this at <a href=\"http://yasgui.org/\" rel=\"noreferrer\">http://yasgui.org/</a> Just type the query and you get the result.</p>\n"},{"tags":["f#","type-providers","f#-data"],"owner":{"account_id":2124011,"reputation":653,"user_id":1886661,"user_type":"registered","accept_rate":9,"profile_image":"https://www.gravatar.com/avatar/e24931e1dd5980a29c2df12214a93b63?s=256&d=identicon&r=PG","display_name":"carstenj","link":"https://stackoverflow.com/users/1886661/carstenj"},"is_answered":true,"view_count":360,"answer_count":1,"score":4,"last_activity_date":1365974895,"creation_date":1365962366,"last_edit_date":1365971991,"question_id":16002406,"body_markdown":"I really like the Freebase and World Bank type providers and I would like to learn more about type providers by writing one on my own. The European Union has an open data program where you can access data through SPARQL/Linked data. Would it be possible to wrap data access to open EU data by means of a type provider or will it be a waste of time trying to figure out how to do it?\r\n\r\nAccess to EU data is described here: http://open-data.europa.eu/en/linked-data","link":"https://stackoverflow.com/questions/16002406/is-it-possible-to-write-a-f-type-provider-to-linked-data","title":"Is it possible to write a F# type provider to linked data?","body":"<p>I really like the Freebase and World Bank type providers and I would like to learn more about type providers by writing one on my own. The European Union has an open data program where you can access data through SPARQL/Linked data. Would it be possible to wrap data access to open EU data by means of a type provider or will it be a waste of time trying to figure out how to do it?</p>\n\n<p>Access to EU data is described here: <a href=\"http://open-data.europa.eu/en/linked-data\" rel=\"nofollow\">http://open-data.europa.eu/en/linked-data</a></p>\n"}],"has_more":false,"quota_max":300,"quota_remaining":259}